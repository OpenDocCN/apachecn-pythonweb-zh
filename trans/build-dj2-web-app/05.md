# 五、使用 Docker 部署

在本章中，我们将了解如何使用托管在亚马逊**电子计算云**（**EC2**中的 Linux 服务器上的 Docker 容器将 MyMDB 部署到生产环境中。我们还将使用**亚马逊网络服务****AWS**的**简单存储服务****S3**来存储用户上传的文件。

我们将做以下几件事：

*   将我们的需求和设置文件拆分为单独的开发和生产设置
*   为 MyMDB 构建 Docker 容器
*   构建数据库容器
*   使用 Docker Compose 启动两个容器
*   将 MyMDB 启动到云中 Linux 服务器上的生产环境中

首先，让我们将需求和设置分开，以便将开发和生产值分开。

# 生产和开发的组织配置

到目前为止，我们保存了一个需求文件和一个`settings.py`文件。这为开发提供了便利。但是，我们不能在生产中使用我们的开发设置。

当前的最佳实践是为每个环境创建一个单独的文件。然后，每个环境的文件导入一个具有共享值的公共文件。我们将在需求和设置文件中使用此模式。

让我们从分解需求文件开始。

# 拆分需求文件

让我们在项目的基础上创建`requirements.common.txt`：

```py
django<2.1
psycopg2
Pillow<4.4.0
```

不管我们所处的环境如何，我们总是需要 Django、博士后司机和枕头（用于`ImageField`课程）。但是，此需求文件从未直接使用。

接下来，我们在`requirements.dev.txt`中列出我们的开发需求：

```py
-r requirements.common.txt
django-debug-toolbar==1.8
```

前面的文件将安装从`requirements.common.txt`（感谢`-r`）到 Django 调试工具栏的所有内容。

对于我们的生产包，我们将使用`requirements.production.txt`：

```py
-r requirements.common.txt
django-storages==1.6.5
boto3==1.4.7
uwsgi==2.0.15
```

这也将从`requirements.common.txt`安装软件包。它还将安装`boto3`和`django-storages`软件包，帮助我们轻松地将文件上传到 S3。`uwsgi`包将提供我们将用于服务 Django 的服务器。

要安装用于生产的软件包，我们现在可以执行以下命令：

```py
$ pip install -r requirements.production.txt
```

接下来，让我们沿着类似的线拆分设置文件。

# 分割设置文件

同样，我们将遵循当前 Django 的最佳实践，将设置文件拆分为以下三个文件：`common_settings.py`、`production_settings.py`和`dev_settings.py`。

# 创建公共 _settings.py

我们将通过重命名当前的`settings.py`文件来创建`common_settings.py`，然后进行本节中提到的更改。

让我们更改`DEBUG = False`以便新设置文件不会*意外*处于调试模式。然后，让我们更改`SECRET_KEY`设置，通过将其行更改为：

```py
SECRET_KEY = os.getenv('DJANGO_SECRET_KEY')
```

我们还要添加一个新设置，`STATIC_ROOT`。`STATIC_ROOT`是 Django 将从我们安装的应用程序中收集所有静态文件的目录，以便于为其提供服务：

```py
STATIC_ROOT = os.path.join(BASE_DIR, 'gathered_static_files')
```

在数据库配置中，我们可以删除所有凭证，但保留`ENGINE`值（为了清楚起见，我们打算在任何地方使用 Postgres）：

```py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
    }
}
```

最后，我们删除`CACHES`设置。这必须在每个环境中进行不同的配置。

接下来，让我们创建一个开发设置文件。

# 创建 dev_settings.py

我们的开发设置将在`django/config/dev_settings.py`中。我们将逐步构建它。

首先，我们将从`common_settings`导入所有内容：

```py
from config.common_settings import *
```

然后，我们将覆盖`DEBUG`和`SECRET_KEY`设置：

```py
DEBUG = True
SECRET_KEY = 'some secret'
```

在开发中，我们希望在调试模式下运行。我们也会感到安全硬编码一个秘密密钥，因为我们知道它不会在生产中使用。

接下来我们更新`INSTALLED_APPS`列表：

```py
INSTALLED_APPS += [
    'debug_toolbar',
]
```

在开发中，我们可以通过在`INSTALLED_APPS`列表中添加一个仅用于开发的应用程序列表来运行额外的应用程序（如 Django 调试工具栏）。

然后，让我们更新数据库配置：

```py
DATABASES['default'].update({
    'NAME': 'mymdb',
    'USER': 'mymdb',
    'PASSWORD': 'development',
    'HOST': 'localhost',
    'PORT': '5432',
})
```

因为我们的开发数据库是本地的，所以我们可以对设置中的值进行硬编码，使文件更简单。如果您的数据库不是本地数据库，请避免在版本控制中检查密码，并使用`os.getenv()`，如在生产中一样。

接下来，让我们更新缓存配置：

```py
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        'LOCATION': 'default-locmemcache',
        'TIMEOUT': 5,
    }
}
```

我们将在开发缓存中使用非常短的超时。

最后，我们需要设置文件上传目录：

```py
# file uploads
MEDIA_ROOT = os.path.join(BASE_DIR, '../media_root')
```

在开发中，我们将上传的文件存储在开发中的本地文件系统中。我们将使用`MEDIA_ROOT`指定要上传到的目录。

Django 调试工具栏也需要一些配置：

```py
# Django Debug Toolbar
INTERNAL_IPS = [
    '127.0.0.1',
]
```

Django 调试工具栏将仅在预定义的 IP 上呈现，因此我们将为其提供本地主机 IP，以便在本地使用它。

我们还可以添加更多只用于开发的应用程序可能需要的设置。

接下来，让我们添加生产设置。

# 创建生产设置.py

让我们在`django/config/production_settings.py`中创建我们的生产设置。

`production_settings.py`与`dev_settings.py`类似，但经常使用`os.getenv()`从环境变量中获取值。这有助于我们将机密（例如密码、API 令牌等）排除在版本控制之外，并将设置与特定服务器分离：

```py
from config.common_settings import * 
DEBUG = False
assert SECRET_KEY is not None, (
    'Please provide DJANGO_SECRET_KEY '
    'environment variable with a value')
ALLOWED_HOSTS += [
    os.getenv('DJANGO_ALLOWED_HOSTS'),
]
```

首先，我们导入公共设置。出于谨慎起见，我们确保调试模式处于关闭状态。

拥有`SECRET_KEY`装置对我们的系统保持安全至关重要。我们`assert`是为了防止 Django 在没有`SECRET_KEY`的情况下启动。`common_settings`模块应该已经通过环境变量进行了设置。

生产网站将从`localhost`以外的域访问。然后，我们通过将`DJANGO_ALLOWED_HOSTS`环境变量添加到`ALLOWED_HOSTS`列表中，告诉 Django 我们正在服务的其他域。

接下来，我们将更新数据库配置：

```py
DATABASES['default'].update({
    'NAME': os.getenv('DJANGO_DB_NAME'),
    'USER': os.getenv('DJANGO_DB_USER'),
    'PASSWORD': os.getenv('DJANGO_DB_PASSWORD'),
    'HOST': os.getenv('DJANGO_DB_HOST'),
    'PORT': os.getenv('DJANGO_DB_PORT'),
})
```

我们使用环境变量中的值更新数据库配置。

然后，需要设置缓存配置。

```py
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        'LOCATION': 'default-locmemcache',
        'TIMEOUT': int(os.getenv('DJANGO_CACHE_TIMEOUT'), ),
    }
}
```

在生产中，我们将接受本地内存缓存的折衷方案。我们使用另一个环境变量在运行时配置超时。

接下来，需要添加文件上载配置设置。

```py
# file uploads
DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY_ID')
AWS_STORAGE_BUCKET_NAME = os.getenv('DJANGO_UPLOAD_S3_BUCKET')
```

在生产中，我们不会将上载的图像存储在容器的本地文件系统中。Docker 的一个核心概念是容器是短暂的。可以停止并删除一个容器，然后用另一个容器替换它。如果我们将上传的图像存储在本地，我们将违背这一理念。

不在本地存储上传文件的另一个原因是，它们也应该从不同的域提供服务（我们在[第 3 章](03.html)、*海报、头像和安全*中讨论了这一点）。我们将使用 S3 存储，因为它既便宜又简单。

`django-storages`应用程序为许多 CDN（包括 S3）提供文件存储后端。我们告诉 Django 通过更改`DEFAULT_FILE_STORAGE`设置来使用 S3。`S3Boto3Storage`后端需要更多设置才能使用 AWS，包括 AWS 访问密钥、AWS 秘密访问密钥和目标存储桶的名称。我们稍后将在 AWS 部分讨论这两个访问密钥。

现在我们的设置已经组织好了，我们可以创建 MyMDB`Dockerfile`。

# 创建 MyMDB Dockerfile

在本节中，我们将为 MyMDB 创建 Dockerfile。Docker 基于图像运行容器。图像由 Dockerfile 定义。Dockerfile 必须扩展另一个 Dockerfile（保留的`scratch`映像是此循环的结束）。

Docker 的理念是每个容器都应该有一个单一的关注点（目的）。这可能意味着它运行一个进程，也可能同时运行多个进程。在我们的例子中，它将同时运行 uWSGI 和 Nginx 进程来提供 MyMDB。

令人困惑的是，Dockerfile 同时引用了预期的*文件名*和*文件类型*。所以`Dockerfile`是一个 Dockerfile。

让我们在名为`Dockerfile`的文件中的项目根目录下创建一个 Dockerfile。Dockerfile 使用自己的语言定义映像中的文件/目录，以及生成映像时需要运行的任何命令。关于编写 Dockerfile 的完整指南不在本章讨论范围之内。相反，我们将逐步构建我们的`Dockerfile`，只讨论最相关的元素。

我们将通过以下六个步骤构建我们的`Dockerfile`：

1.  初始化基本映像并将源代码添加到映像
2.  安装软件包
3.  收集静态文件
4.  配置 Nginx
5.  配置 uWSGI
6.  清理不必要的资源

# 开始我们的 Dockerfile

我们的`Dockerfile`的第一部分告诉 Docker 使用哪个图像作为基础，添加我们的代码，并创建一些公共目录：

```py
FROM phusion/baseimage

# add code and directories
RUN mkdir /mymdb
WORKDIR /mymdb
COPY requirements* /mymdb/
COPY django/ /mymdb/django
COPY scripts/ /mymdb/scripts
RUN mkdir /var/log/mymdb/
RUN touch /var/log/mymdb/mymdb.log
```

让我们更详细地了解这些说明：

*   `FROM`：这是 Dockerfile 中必需的。`FROM`告诉 Docker 使用什么图像作为我们图像的基础图像。我们将使用`phusion/baseimage`，因为它提供了很多方便的设施，并且占用的内存非常少。这是一个为 Docker Ubuntu 定制的图像，带有一个较小的易于使用的名为 runit 的 init 服务管理器（而不是 Ubuntu 的 upstart）。
*   `RUN`：作为构建图像的一部分，执行命令。`RUN mkdir /mymdb`创建我们将在其中存储文件的目录。
*   `WORKDIR`：这为我们未来的所有`RUN`命令设置了工作目录。
*   `COPY`：这会将文件系统中的文件（或目录）添加到映像中。源路径相对于包含我们的`Dockerfile`的目录。最好将目标路径设置为绝对路径。

我们还将引用一个名为`scripts`的新目录。让我们在项目目录的根目录下创建它：

```py
$ mkdir scripts
```

作为配置和构建新映像的一部分，我们将创建一些小的 bash 脚本，这些脚本将保存在`scripts`目录中。

# 在 Dockerfile 中安装程序包

接下来，我们将告诉我们的`Dockerfile`安装我们需要的所有软件包：

```py
RUN apt-get -y update
RUN apt-get install -y \
    nginx \
    postgresql-client \
    python3 \
    python3-pip
RUN pip3 install virtualenv
RUN virtualenv /mymdb/venv
RUN bash /mymdb/scripts/pip_install.sh /mymdb
```

我们使用`RUN`语句来安装 Ubuntu 软件包并创建一个虚拟环境。为了将 Python 软件包安装到虚拟环境中，我们将在`scripts/pip_install.sh`中创建一个小脚本：

```py
#!/usr/bin/env bash

root=$1
source $root/venv/bin/activate

pip3 install -r $root/requirements.production.txt
```

前面的脚本只是激活虚拟环境并在我们的生产需求文件上运行`pip3 install`。

在 DOCKER 文件中间调试长命令通常很困难。在脚本中包装命令可以使它们更易于调试。如果某些东西不工作，您可以使用`docker exec -it bash -l`命令连接到容器，并正常调试脚本。

# 在 Dockerfile 中收集静态文件

静态文件是支持我们网站的 CSS、JavaScript 和图像。静态文件可能并不总是由我们创建的。一些静态文件来自已安装的 Django 应用程序（例如，Django admin）。让我们更新我们的`Dockerfile`以收集静态文件：

```py
# collect the static files
RUN bash /mymdb/scripts/collect_static.sh /mymdb
```

同样，我们将命令包装在脚本中。让我们在`scripts/collect_static.sh`中添加以下脚本：

```py
#!/usr/bin/env bash

root=$1
source $root/venv/bin/activate

export DJANGO_CACHE_TIMEOUT=100
export DJANGO_SECRET_KEY=FAKE_KEY
export DJANGO_SETTINGS_MODULE=config.production_settings

cd $root/django/

python manage.py collectstatic
```

前面的脚本激活我们在前面的代码中创建的虚拟环境，并设置所需的环境变量。在这种情况下，只要变量存在，这些值中的大多数都无关紧要。然而，`DJANGO_SETTINGS_MODULE`环境变量非常重要。Django 使用`DJANGO_SETTINGS_MODULE`环境变量查找设置模块。如果我们不设置它并且没有`config/settings.py`，那么 Django 将不会启动（即使`manage.py`命令也会失败）。

# 将 Nginx 添加到 Dockerfile

要配置 Nginx，我们将添加一个配置文件和一个 runit 服务脚本：

```py
COPY nginx/mymdb.conf /etc/nginx/sites-available/mymdb.conf
RUN rm /etc/nginx/sites-enabled/*
RUN ln -s /etc/nginx/sites-available/mymdb.conf /etc/nginx/sites-enabled/mymdb.conf

COPY runit/nginx /etc/service/nginx
RUN chmod +x /etc/service/nginx/run
```

# 配置 Nginx

让我们在`nginx/mymdb.conf`中添加一个 Nginx 配置文件：

```py
# the upstream component nginx needs
# to connect to
upstream django {
    server 127.0.0.1:3031;
}

# configuration of the server
server {

    # listen on all IPs on port 80
    server_name 0.0.0.0;
    listen      80;
    charset     utf-8;

    # max upload size
    client_max_body_size 2M;

    location /static {
        alias /mymdb/django/gathered_static_files;
    }

    location / {
        uwsgi_pass  django;
        include     /etc/nginx/uwsgi_params;
    }

}
```

Nginx 将负责以下两件事：

*   提供静态文件服务（URL 以`/static`开头）
*   将所有其他请求传递给 uWSGI

`upstream`块描述了 Django（uWSGI）服务器的位置。在`location /`块中，nginx 被指示使用 uWSGI 协议将请求传递到上游服务器。`include /etc/nginx/uwsgi_params`文件描述了如何映射头，以便 uWSGI 理解它们。

`client_max_body_size`是一个重要的设置。它描述了文件上载的最大大小。将此值保留得太大可能会暴露漏洞，因为攻击者可能会用大量请求淹没服务器。

# 创建 Nginx runit 服务

为了让`runit`知道如何启动 Nginx，我们需要提供一个`run`脚本。我们的`Dockerfile`希望它位于`runit/nginx/run`：

```py
#!/usr/bin/env bash

exec /usr/sbin/nginx \
    -c /etc/nginx/nginx.conf \
    -g "daemon off;"
```

`runit`不希望它的服务分开一个单独的进程，所以我们使用`daemon off`运行 Nginx。此外，`runit`希望我们使用`exec`替换脚本的进程，即新的 Nginx 进程。

# 将 uWSGI 添加到 Dockerfile

我们之所以使用 uWSGI，是因为它通常被列为最快的 WSGI 应用服务器。让我们在`Dockerfile`中添加以下代码进行设置：

```py
# configure uwsgi
COPY uwsgi/mymdb.ini /etc/uwsgi/apps-enabled/mymdb.ini
RUN mkdir -p /var/log/uwsgi/
RUN touch /var/log/uwsgi/mymdb.log
RUN chown www-data /var/log/uwsgi/mymdb.log
RUN chown www-data /var/log/mymdb/mymdb.log

COPY runit/uwsgi /etc/service/uwsgi
RUN chmod +x /etc/service/uwsgi/run
```

这指示 Docker 使用`mymdb.ini`文件配置 uWSGI，创建日志目录，并添加 uWSGI runit 服务。为了让 runit 启动 uWSGI 服务，我们授予 runit 脚本使用`chmod`命令执行的权限。

# 配置 uWSGI 以运行 MyMDB

让我们在`uwsgi/mymdb.ini`中创建 uWSGI 配置：

```py
[uwsgi]
socket = 127.0.0.1:3031
chdir = /mymdb/django/
virtualenv = /mymdb/venv
wsgi-file = config/wsgi.py
env = DJANGO_SECRET_KEY=$(DJANGO_SECRET_KEY)
env = DJANGO_LOG_LEVEL=$(DJANGO_LOG_LEVEL)
env = DJANGO_ALLOWED_HOSTS=$(DJANGO_ALLOWED_HOSTS)
env = DJANGO_DB_NAME=$(DJANGO_DB_NAME)
env = DJANGO_DB_USER=$(DJANGO_DB_USER)
env = DJANGO_DB_PASSWORD=$(DJANGO_DB_PASSWORD)
env = DJANGO_DB_HOST=$(DJANGO_DB_HOST)
env = DJANGO_DB_PORT=$(DJANGO_DB_PORT)
env = DJANGO_CACHE_TIMEOUT=$(DJANGO_CACHE_TIMEOUT)
env = AWS_ACCESS_KEY_ID=$(AWS_ACCESS_KEY_ID)
env = AWS_SECRET_ACCESS_KEY_ID=$(AWS_SECRET_ACCESS_KEY_ID)
env = DJANGO_UPLOAD_S3_BUCKET=$(DJANGO_UPLOAD_S3_BUCKET)
env = DJANGO_LOG_FILE=$(DJANGO_LOG_FILE)
processes = 4
threads = 4
```

让我们仔细看看这些设置：

*   `socket`告知 uWSGI 使用其自定义`uwsgi`协议在`127.0.0.1:3031`上打开一个套接字（令人困惑的是，协议和服务器名称相同）。
*   `chdir`更改进程的工作目录。所有路径都需要相对于此位置。
*   `virtualenv`告知 uWSGI 项目虚拟环境的路径。
*   每个`env`指令为我们的流程设置一个环境变量。我们可以在代码中使用`os.getenv()`来访问它们（例如，`production_settings.py`。
*   `$(...)`是来自 uWSGI 流程自身环境的参考环境变量（例如，`$(DJANGO_SECRET_KEY )`。
*   `proccesses`设置我们应该运行多少进程。
*   `threads`设置每个进程应该有多少线程。

需要根据生产性能对`processes`和`threads`设置进行微调。

# 创建 uWSGI runit 服务

为了让 runit 知道如何启动 uWSGI，我们需要提供一个`run`脚本。我们的`Dockerfile`希望它在`runit/uwsgi/run`中。此脚本比我们用于 Nginx 的脚本更复杂：

```py
#!/usr/bin/env bash

source /mymdb/venv/bin/activate

export PGPASSWORD="$DJANGO_DB_PASSWORD"
psql \
    -h "$DJANGO_DB_HOST" \
    -p "$DJANGO_DB_PORT" \
    -U "$DJANGO_DB_USER" \
    -d "$DJANGO_DB_NAME"

if [[ $? != 0 ]]; then
    echo "no db server"
    exit 1
fi

pushd /mymdb/django

python manage.py migrate

if [[ $? != 0 ]]; then
    echo "can't migrate"
    exit 2
fi
popd

exec /sbin/setuser www-data \
    uwsgi \
    --ini /etc/uwsgi/apps-enabled/mymdb.ini \
    >> /var/log/uwsgi/mymdb.log \
    2>&1
```

此脚本执行以下三项操作：

*   检查是否可以连接到数据库，否则退出
*   运行所有迁移或在失败时退出
*   启动 uWSGI

runit 要求我们使用`exec`启动流程，以便 uWSGI 将替换`run`脚本的流程。

# 完成我们的 Dockerfile

作为最后一步，我们将清理并记录我们正在使用的端口：

```py
RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

EXPOSE 80
```

`EXPOSE`语句记录了我们正在使用的端口。重要的是，它实际上没有打开任何端口。我们在运行容器时必须这样做。

接下来，让我们为数据库创建一个容器。

# 创建数据库容器

我们需要一个数据库来在生产中运行 Django。PostgreSQL Docker 社区为我们提供了一个非常强大的 Postgres 映像，我们可以扩展它。

让我们在`docker/psql/Dockerfile`中为我们的数据库创建另一个容器：

```py
FROM postgres:10.1

ADD make_database.sh /docker-entrypoint-initdb.d/make_database.sh
```

此`Dockerfile`的基础图像将使用 Postgres 10.1。它还有一个方便的工具，可以在`/docker-entrypoint-initdb.d`中执行任何 shell 或 SQL 脚本，作为 DB 初始化的一部分。我们将利用这一点创建 MyMDB 数据库和用户。

让我们在`docker/psql/make_database.sh`中创建数据库初始化脚本：

```py
#!/usr/bin/env bash

psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" <<-EOSQL
    CREATE DATABASE $DJANGO_DB_NAME;
    CREATE USER $DJANGO_DB_USER;
    GRANT ALL ON DATABASE $DJANGO_DB_NAME TO "$DJANGO_DB_USER";
    ALTER USER $DJANGO_DB_USER PASSWORD '$DJANGO_DB_PASSWORD';
    ALTER USER $DJANGO_DB_USER CREATEDB;
EOSQL
```

我们在前面的代码中使用了一个 shell 脚本，以便可以使用环境变量来填充 SQL。

现在我们已经准备好了这两个容器，让我们确保可以通过注册和配置 AWS 来实际启动它们。

# 在 AWS S3 上存储上载的文件

我们希望 MyMDB 将文件保存到 S3。为了实现这一点，我们需要注册 AWS，然后将 shell 配置为能够使用 AWS。

# 注册 AWS

要注册，请导航至[https://aws.amazon.com](https://aws.amazon.com) 并遵循他们的指示。请注意，注册是免费的。

在撰写本书时，我们将使用的资源都在 AWS 免费层中。免费层的某些元素仅适用于第一年的新帐户。在执行任何 AWS 命令之前，请检查您的帐户的资格。

# 设置 AWS 环境

要与 AWSAPI 交互，我们需要以下两个令牌：访问密钥和秘密访问密钥。此密钥对定义对帐户的访问。

要生成一对令牌，请转至[https://console.aws.amazon.com/iam/home?region=us-west-2#/security_credential_uUt1]，单击访问密钥，然后单击创建新访问密钥按钮。如果您丢失了一个秘密访问密钥，则无法检索该密钥，因此请确保将其保存在安全的地方。](https://console.aws.amazon.com/iam/home?region=us-west-2#/security_credential)

前面的 AWS 控制台链接将为您的根帐户生成令牌。这在我们测试的时候很好。将来，您应该使用 AWS IAM 权限系统使用户具有有限的权限。

接下来，我们来安装 AWS**命令行界面**（**CLI**）：

```py
$ pip install awscli
```

然后，我们需要使用密钥和区域配置 AWS 命令行工具。`aws`命令提供了一个交互`configure`子命令来完成此操作。让我们在命令行上运行它：

```py
$ aws configure
 AWS Access Key ID [None]: <Your ACCESS key>
 AWS Secret Access Key [None]: <Your secret key>
 Default region name [None]: us-west-2
 Default output format [None]: json
```

`aws configure`命令将您在主目录的`.aws`目录中输入的值存储起来。

要确认新帐户设置正确，请请求 EC2 实例列表（应该没有）：

```py
$ aws ec2 describe-instances
{
    "Reservations": []
}
```

# 创建文件上传 bucket

S3 被组织成桶。每个 bucket 必须具有唯一的名称（在所有 AWS 中都是唯一的）。每个 bucket 还将有一个控制访问的策略。

让我们通过执行以下命令（将`BUCKET_NAME`更改为您自己的唯一名称）为文件上载创建一个 bucket：

```py
$ export AWS_ACCESS_KEY=#your value
$ export AWS_SECRET_ACCESS_KEY=#yourvalue
$ aws s3 mb s3://BUCKET_NAME
```

为了让未经身份验证的用户访问我们存储桶中的文件，我们必须设置一个策略。让我们在`AWS/mymdb-bucket-policy.json`中创建策略：

```py
{
    "Version": "2012-10-17",
    "Id": "mymdb-bucket-policy",
    "Statement": [
        {
            "Sid": "allow-file-download-stmt",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::BUCKET_NAME/*"
        }
    ]
}
```

确保将`BUCKET_NAME`更新为您的 bucket 名称。

现在，我们可以使用 AWS CLI 在您的 bucket 上应用该策略：

```py
$ aws s3api put-bucket-policy --bucket BUCKET_NAME --policy "$(cat AWS/mymdb-bucket-policy.json)"
```

请确保记住您的 bucket 名称、AWS 访问密钥和 AWS 秘密访问密钥，因为我们将在下一节中使用它们。

# 使用 Docker 编写

我们现在已经准备好了生产部署的所有部分。Docker Compose 是 Docker 让多个容器一起工作的方式。Docker Compose 由命令行工具`docker-compose`组成；配置文件`docker-compose.yml`；以及一个环境变量文件`.env`。我们将在项目目录的根目录下创建这两个文件。

永远不要将`.env`文件签入版本控制。那是你的秘密所在。别让它们泄露出去。

首先，让我们在`.env`中列出我们的环境变量：

```py
# Django settings
DJANGO_SETTINGS_MODULE=config.production_settings
DJANGO_SECRET_KEY=#put your secret key here
DJANGO_LOG_LEVEL=DEBUG
DJANGO_LOG_FILE=/var/log/mymdb/mymdb.log
DJANGO_ALLOWED_HOSTS=# put your domain here
DJANGO_DB_NAME=mymdb
DJANGO_DB_USER=mymdb
DJANGO_DB_PASSWORD=#put your password here
DJANGO_DB_HOST=db
DJANGO_DB_PORT=5432
DJANGO_CACHE_TIMEOUT=200

AWS_ACCESS_KEY_ID=# put aws key here
AWS_SECRET_ACCESS_KEY_ID=# put your secret key here
DJANGO_UPLOAD_S3_BUCKET=# put BUCKET_NAME here

# Postgres settings
POSTGRES_PASSWORD=# put your postgress admin password here
```

其中许多值可以硬编码，但有几个值需要为项目设置：

*   `DJANGO_SECRET_KEY`：Django 密钥用作 Django 加密的种子的一部分
*   `DJANGO_DB_PASSWORD`：这是 Django 的 MyMDB 数据库用户的密码
*   `AWS_ACCESS_KEY_ID`：您的 AWS 访问密钥
*   `AWS_SECRET_ACCESS_KEY_ID`：您的 AWS 秘密访问密钥
*   `DJANGO_UPLOAD_S3_BUCKET`：你的桶名
*   `POSTGRES_PASSWORD`：Postgres 数据库超级用户密码（与 MyMDB 数据库用户不同）
*   `DJANGO_ALLOWED_HOSTS`：我们将从中提供服务的域（我们将在启动 EC2 实例后填写此字段）

接下来，我们在`docker-compose.yml`中定义我们的容器如何协同工作：

```py
version: '3'

services:
  db:
    build: docker/psql
    restart: always
    ports:
      - "5432:5432"
    environment:
      - DJANGO_DB_USER
      - DJANGO_DB_NAME
      - DJANGO_DB_PASSWORD
  web:
    build: .
    restart: always
    ports:
      - "80:80"
    depends_on:
      - db
    environment:
      - DJANGO_SETTINGS_MODULE
      - DJANGO_SECRET_KEY
      - DJANGO_LOG_LEVEL
      - DJANGO_LOG_FILE
      - DJANGO_ALLOWED_HOSTS
      - DJANGO_DB_NAME
      - DJANGO_DB_USER
      - DJANGO_DB_PASSWORD
      - DJANGO_DB_HOST
      - DJANGO_DB_PORT
      - DJANGO_CACHE_TIMEOUT
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY_ID
      - DJANGO_UPLOAD_S3_BUCKET
```

这个组合文件描述了组成 MyMDB 的两个服务（`db`和`web`。让我们回顾一下我们使用的配置选项：

*   `build`：构建上下文的路径。一般来说，构建上下文是一个带有`Dockerfile`的目录。所以，`db`使用`psql`目录，`web`使用`.`目录（项目根目录，有一个`Dockerfile`）。
*   `ports`：端口映射列表，描述如何将连接从主机上的端口路由到容器上的端口。在我们的情况下，我们不会改变任何端口。
*   `environment`：每个服务的环境变量。我们使用的格式意味着我们要从`.env`文件中获取值。但是，您可以使用`MYVAR=123`语法硬编码值。
*   `restart`：这是容器的重启策略。`always`表示如果容器因任何原因停止，Docker 应始终尝试重新启动容器。
*   `depends_on`：这告诉 Docker 在`web`容器之前启动`db`容器。然而，我们仍然不能确定 Postgres 是否会在 uWSGI 之前启动，所以我们需要检查运行脚本中的数据库是否已启动。

# 跟踪环境变量

我们的生产配置严重依赖于环境变量。让我们回顾一下`os.getenv()`在 Django 中访问它之前必须遵循的步骤：

1.  在`.env`中列出变量
2.  在`docker-compose.yml`中包含环境选项`environment`下的变量
3.  将 uWSGI ini 文件变量包含在`env`中
4.  使用`os.getenv`访问变量

# 在本地运行 Docker Compose

现在我们已经配置了 Docker 容器和 Docker Compose，可以运行这些容器了。Docker Compose 的优点之一是它可以在任何地方提供相同的环境。这意味着我们可以在本地运行 Docker Compose，获得与生产环境完全相同的环境。不必担心会有额外的进程或跨环境的不同分布。让我们在本地运行 Docker Compose。

# 安装 Docker

要完成本章的其余部分，必须在计算机上安装 Docker。Docker，Inc.从其网站[免费提供 Docker 社区版 https://docker.com](https://docker.com) 。Docker Community Edition 安装程序是 Windows 和 Mac 上易于使用的向导。Docker，Inc.还为大多数主要 Linux 发行版提供官方软件包。

一旦您安装了它，您就可以执行接下来的所有步骤。

# 使用 Docker 编写

要在本地启动容器，请运行以下命令：

```py
$ docker-compose up -d 
```

`docker-compose up`构建并启动我们的容器。`-d`选项将 Compose 从外壳中分离出来。

要检查我们的集装箱是否在运行，我们可以使用`docker ps`：

```py
$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                          NAMES
0bd7f7203ea0        mymdb_web           "/sbin/my_init"          52 seconds ago      Up 51 seconds       0.0.0.0:80->80/tcp, 8031/tcp   mymdb_web_1
3b9ecdcf1031        mymdb_db            "docker-entrypoint..."   46 hours ago        Up 52 seconds       0.0.0.0:5432->5432/tcp         mymdb_db_1
```

要查看 Docker 日志，可以使用`docker logs`命令记录启动脚本的输出：

```py
$ docker logs mymdb_web_1
```

要访问容器内的 shell（以便您可以检查文件或查看应用程序日志），请使用此`docker exec`命令启动 bash：

```py
$ docker exec -it mymdb_web_1 bash -l
```

要停止容器，请使用以下命令：

```py
$ docker-compose stop
```

要停止容器并*删除*它们，请使用以下命令：

```py
$ docker-compose down
```

删除容器时，将删除其中的所有数据。这对于 Django 容器来说不是问题，因为它不包含任何数据。但是，如果您删除 db 容器，您*将丢失数据库的数据*。生产时要小心。

# 通过容器注册表共享容器

现在我们有了一个工作容器，我们可能想让它更容易访问。Docker 有容器注册表的概念。您可以将容器推送到容器注册表，使其公开或仅对您的团队可用。

最流行的 Docker 容器注册表是 Docker Hub（[https://hub.docker.com](https://hub.docker.com) ）。您可以免费创建一个帐户，在编写本书时，每个帐户都有一个免费的私有存储库和无限的公共存储库。大多数云提供商也有 docker 存储库托管设施（尽管价格可能有所不同）。

本节其余部分假设您已配置主机。我们将使用 Docker Hub 作为示例，但所有步骤都是相同的，无论容器存储库由谁托管。

要共享容器，您需要执行以下操作：

1.  登录到 Docker 注册表
2.  给我们的集装箱贴上标签
3.  推送到 Docker 注册表

让我们从登录 Docker 注册表开始：

```py
$ docker login -u USERNAME -p PASSWORD docker.io
```

`USERNAME`和`PASSWORD`值必须与您在 Docker Hub 上的帐户使用的值相同。`docker.io`是 Docker Hub 的容器注册域。如果您使用的是不同的容器注册表主机，则需要更改域。

现在我们已经登录，让我们重建并标记容器：

```py
$ docker build . -t USERNAME/REPOSITORY:latest
```

将您的`USERNAME`和`REPOSITORY`值替换为您的值。`:latest`后缀是构建的标记。我们可以在同一个存储库中有许多不同的标签（例如，`development`、`stable`和`1.x`）。Docker 中的标签与版本控制中的标签非常相似；它们帮助我们快速、轻松地找到特定的物品。`:latest`是最新版本的通用标签（尽管可能不稳定）。

最后，让我们将标记的构建推送到存储库：

```py
$ docker push USERNAME/REPOSITORY:latest
```

Docker 将向我们显示其上传进度，然后在成功后显示 SHA256 摘要。

当我们将 Docker 映像推送到远程存储库时，我们需要注意映像上存储的任何私有数据。我们在`Dockerfile`中创建或添加的所有文件都包含在推送的图像中。就像我们不想在存储在远程存储库中的代码中硬编码密码一样，我们也不想在可能存储在远程服务器上的 Docker 映像中存储敏感数据（如密码）。这是我们强调将密码存储在环境变量中而不是硬编码它们的另一个原因。

伟大的现在，您可以与其他团队成员共享回购协议，以运行 Docker 容器。

接下来，让我们启动我们的容器。

# 在云中的 Linux 服务器上启动容器

现在一切都正常了，我们可以将其部署到 internet 上。我们可以使用 Docker 将容器部署到任何 Linux 服务器。大多数使用 Docker 的人都使用云提供商来提供 Linux 服务器主机。在我们的例子中，我们将使用 AWS。

在上一节中，当我们使用`docker-compose`时，我们实际上是在使用它向机器上运行的 Docker 服务发送命令。Docker Machine 提供了一种管理运行 Docker 的远程服务器的方法。我们将使用`docker-machine`启动一个 EC2 实例，它将承载我们的 Docker 容器。

启动一个 EC2 实例可能要花钱。在撰写本书时，我们将使用一个符合 AWS 免费层`t2.micro`条件的实例。但是，您有责任检查 AWS 自由层的条款。

# 启动 Docker EC2 虚拟机

我们将把我们的 EC2 虚拟机（称为 EC2 实例）启动到我们账户的**虚拟私有云**（**VPC**）。但是，每个帐户都有一个唯一的专有网络 ID。要获取您的专有网络 ID，请运行以下命令：

```py
$ export AWS_ACCESS_KEY=#your value
$ export AWS_SECRET_ACCESS_KEY=#yourvalue
$ export AWS_DEFAULT_REGION=us-west-2
$ aws ec2 describe-vpcs | grep VpcId
            "VpcId": "vpc-a1b2c3d4",
```

前面代码中使用的值不是实际值。

现在我们知道了我们的 VPC ID，我们可以使用`docker-machine`来启动 EC2 实例：

```py
$ docker-machine create \
     --driver amazonec2 \
     --amazonec2-instance-type t2.micro \
     --amazonec2-vpc-id vpc-a1b2c3d4 \
     --amazonec2-region us-west-2 \
     mymdb-host
```

这告诉 Docker Machine 在`us-west-2`区域和提供的 VPC 中启动一个 EC2`t2.micro`实例。Docker Machine 负责确保在服务器上安装并启动 Docker 守护程序。在 Docker Machine 中引用此 EC2 实例时，我们将其命名为`mymdb-host`。

实例启动时，我们可以向 AWS 询问实例的公共 DNS 名称：

```py
$ aws ec2 describe-instances | grep -i publicDnsName
```

即使只有一个实例启动，上述命令也可能返回相同值的多个副本。将结果作为`DJANGO_ALLOWED_HOSTS`放入`.env`文件中。

所有 EC2 实例都受到由其安全组确定的防火墙的保护。Docker 机器在启动我们的实例时自动为我们的服务器创建了一个安全组。为了让我们的 HTTP 请求进入我们的机器，我们需要在`docker-machine`安全组中打开端口`80`，如下所示：

```py
$ aws ec2 authorize-security-group-ingress \
    --group-name docker-machine \
    --protocol tcp \
    --port 80 \
    --cidr 0.0.0.0/0
```

现在一切都设置好了，我们可以将`docker-compose`配置为与我们的远程服务器通话并打开我们的容器：

```py
$ eval $(docker-machine env mymdb-host)
$ docker-compose up -d
```

祝贺 MyMDB 处于生产环境中。导航到`DJANGO_ALLOWED_HOSTS`中使用的地址查看。

此处的说明主要介绍如何启动 AWS Linux 服务器。但是，所有 Docker 命令对于 Google Cloud、Azure 和其他主要云提供商都有相同的选项。甚至还有一个*通用*选项可用于任何 Linux 服务器，尽管您的里程数可能因 Linux 发行版和 Docker 版本而异。

# 关闭 Docker EC2 虚拟机

Docker machine 还可用于停止运行 Docker 的 VM，如以下代码段所示：

```py
$ export AWS_ACCESS_KEY=#your value
$ export AWS_SECRET_ACCESS_KEY=#yourvalue
$ export AWS_DEFAULT_REGION=us-west-2
$ eval $(docker-machine env mymdb-host)
$ docker-machine stop mymdb-host 
```

这将停止 EC2 实例并销毁其中的所有容器。如果希望保留数据库，请确保通过运行前面的`eval`命令，然后使用`docker exec -it mymdb_db_1 bash -l`打开 shell 来备份数据库。

# 总结

在本章中，我们将 MyMDB 发布到 internet 上的生产 Docker 环境中。我们已经使用 Dockerfile 为 MyMDB 创建了一个 Docker 容器。我们使用 Docker Compose 使 MyMDB 与 PostgreSQL 数据库（也在 Docker 容器中）一起工作。最后，我们使用 Docker 机器在 AWS 云上启动了容器。

祝贺您现在已经运行了 MyMDB。

在下一章中，我们将实现堆栈溢出。