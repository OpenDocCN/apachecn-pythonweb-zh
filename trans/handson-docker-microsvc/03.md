# 使用 Docker 构建、运行和测试您的服务

在上一章中设计了一个可工作的 RESTful 微服务之后，我们将在本章中看到如何以 Docker 的方式*使用它，将服务封装到一个自包含的容器中，以便它是不可变的，并且可以自行部署。本章非常明确地描述了服务的依赖关系及其使用方法。运行服务的主要方式是将其作为 web 服务器运行，但也可以执行其他操作，如运行单元测试、生成报告等。我们还将了解如何在本地计算机上部署服务进行测试，以及如何通过映像存储库共享服务。*

本章将介绍以下主题：

*   使用 Dockerfile 构建您的服务
*   使用不可变容器操作
*   配置您的服务
*   在本地部署 Docker 服务
*   将 Docker 映像推送到远程注册表

在本章结束时，您将了解如何使用 Docker、创建基本服务、构建映像并运行它。您还将了解如何共享要在另一台计算机上运行的映像。

# 技术要求

对于本章，您需要安装 Docker，版本 18.09 或更高版本。见官方文件（[https://docs.docker.com/install/](https://docs.docker.com/install/) 了解如何为您的平台执行此操作。

If you install Docker in Linux, you may have to configure the server to run for non-root access. Check the documentation at [https://docs.docker.com/install/linux/linux-postinstall/](https://docs.docker.com/install/linux/linux-postinstall/).

使用以下命令检查版本：

```py
$ docker version
Client: Docker Engine - Community
 Version: 18.09.2
 API version: 1.39
 Go version: go1.10.8
 Git commit: 6247962
 Built: Sun Feb 10 04:12:39 2019
 OS/Arch: darwin/amd64
 Experimental: false
```

您还需要安装 Docker Compose 1.24.0 或更高版本。请注意，在某些安装（如 macOS）中，这是为您自动安装的。检查 Docker 文档（[中的安装说明 https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/) ：

```py
$ docker-compose version
docker-compose version 1.24.0, build 0aa5906
docker-py version: 3.7.2
CPython version: 3.7.3
OpenSSL version: OpenSSL 1.0.2r 26 Feb 2019
```

该代码可在 GitHub 上获得，位于以下目录：[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter03](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter03) 。在[第 2 章](02.html)中有`ThoughtsBackend`的副本*使用 Python*创建 REST 服务，但代码略有不同。我们将在本章中讨论这些差异。

# 使用 Dockerfile 构建您的服务

这一切都从一个容器开始。正如我们在[第 1 章](01.html)*中所说的，容器是一个打包的软件包，以标准方式封装。它们是可以独立运行的软件单元，因为它们是完全独立的。要制作一个容器，我们需要构建它。*

Remember our description of a container as a process surrounded by its own filesystem. Building a container constructs this filesystem.

要使用 Docker 构建容器，我们需要对其内容进行定义。文件系统是通过层层应用创建的。每个 Dockerfile（生成容器的配方）都包含生成容器步骤的定义。

例如，让我们创建一个非常简单的 Dockerfile。创建一个名为`example.txt`的文件，其中包含一些示例文本，另一个名为`Dockerfile.simple`的文件包含以下内容：

```py
# scratch is a special container that is totally empty
FROM scratch
COPY example.txt /example.txt
```

现在使用以下命令构建它：

```py
$ # docker build -f <dockerfile> --tag <tag> <context>
$   docker build -f Dockerfile.simple --tag simple .
Sending build context to Docker daemon 3.072kB
Step 1/2 : FROM scratch
 --->
Step 2/2 : COPY example.txt /example.txt
 ---> Using cache
 ---> f961aef9f15c
Successfully built f961aef9f15c
Successfully tagged simple:latest

$ docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
simple latest f961aef9f15c 4 minutes ago 11B
```

这将创建一个只包含`example.txt`文件的 Docker 映像。它不是很有用，但是非常小，只有 11 个字节。这是因为它继承自空容器`scratch`。然后，它在`/example.txt`容器中的位置内复制`example.txt`文件。

让我们看一看 Apple T0.命令。Dockerfile 是用`-f`参数定义的，生成图像的标签是用`--tag` 定义的，`context`参数是用点（`.`定义的。`context`参数是指在 Dockerfile 中的步骤中定义的文件的查找位置。

图像还具有自动分配的图像 ID`f961aef9f15c`。这是文件系统内容的散列。我们稍后将了解为什么这是相关的。

# 执行命令

前一个容器不是很令人兴奋。完全从头开始创建您自己的容器是完全可能的，但是，通常，您将寻找一个包含某种 Linux 发行版的基线，它允许您对容器做一些有用的事情。

正如我们在`FROM`命令中看到的，我们可以从前面的容器开始。我们将使用 Alpine Linux（[https://alpinelinux.org/](https://alpinelinux.org/) ）本书的发行版，尽管还有其他发行版，如 Ubuntu 和 CentOS。在[查看文章 https://sweetcode.io/linux-distributions-optimized-hosting-docker/](https://sweetcode.io/linux-distributions-optimized-hosting-docker/) 针对 Docker 集装箱的分发。

Why Alpine Linux? It is arguably the most popular distribution for Docker systems because it has a very small footprint and it's aimed at security. It is well-maintained and regularly updated and patched. It also has a complete package management system that allows you to install most of the common tools for web services easily. The base image is only around 5 MB in size and contains a working Linux operating system.

It has a couple of quirks when working with it, such as using its own package management, called `apk`, but it's easy to use and is almost a straight-on drop replacement for common Linux distributions.

以下 Dockerfile 将从基本`alpine`容器继承并添加`example.txt`文件：

```py
FROM alpine

RUN mkdir -p /opt/
COPY example.txt /opt/example.txt
```

此容器允许我们运行命令，因为通常的命令行实用程序包括：

```py
$ docker build -f Dockerfile.run --tag container-run .
Sending build context to Docker daemon 4.096kB
Step 1/3 : FROM alpine
 ---> 055936d39205
Step 2/3 : RUN mkdir -p /opt/
 ---> Using cache
 ---> 4f565debb941
Step 3/3 : COPY example.txt /opt/example.txt
 ---> Using cache
 ---> d67a72454d75
Successfully built d67a72454d75
Successfully tagged container-run:latest

$ # docker run <image name> <command> 
$   docker run container-run cat /opt/example.txt
An example file
```

注意`cat /opt/example.txt`命令行是如何执行的。这实际上是在容器内部发生的。我们在`stdout`控制台的`stdout`中打印结果。但是，如果创建了一个文件，当容器停止时，该文件不会保存在本地文件系统中，而只保存在容器中：

```py
$ ls
Dockerfile.run example.txt
$ docker run container-run /bin/sh -c 'cat /opt/example.txt > out.txt'
$ ls
Dockerfile.run example.txt
```

该文件实际上保存在已停止的容器中。一旦容器完成运行，Docker 将停止该容器，直到将其移除。您可以通过`docker ps -a`命令看到停止的容器。停止的容器不是很有趣，尽管它的文件系统保存在磁盘上。

When running web services, the command being run won't stop; it will keep running until stopped. Remember what we said before about a container being a process with a filesystem attached. The command running is the key to the container.

通过添加以下内容，可以添加默认命令，该命令将在未发出命令时执行：

```py
CMD cat /opt/example.txt
```

使用以下命令使其自动运行：

```py
$ docker run container-run
An example file
```

定义标准命令使容器变得非常简单。只要运行它，它就会执行配置为执行的任何操作。请记住在容器中包含默认命令。

我们还可以在容器中执行 shell 并与之交互。记住添加`-it`标志以保持连接正常打开，`-i`保持`stdin`打开，`-t`创建一个伪终端，您可以将其记为交互终端：

```py
$ docker run -it container-run /bin/sh
/ # cd opt/
/opt # ls
example.txt
/opt # cat example.txt
An example file
/opt # exit
$
```

这在发现问题或执行探索性测试时非常有用。

# 理解 Docker 缓存

构建图像时的一个主要混淆点是理解 Docker 层是如何工作的。

Dockerfile 上的每个命令都在上一层的顶部连续执行。如果您对 Git 感到满意，您会注意到这个过程是类似的。每个层仅存储对上一步的更改：

![](assets/14605f6c-28fa-4b09-be18-960f278ac5f0.png)

这使得 Docker 能够非常积极地缓存，因为在计算更改之前的任何层都已经存在。例如，在本例中，我们使用`apk update`更新可用软件包，然后安装`python3`软件包，然后再复制`example.txt`文件。对`example.txt`文件的任何更改将仅在`be086a75fe23`层上执行最后两个步骤。这加快了图像的重建速度。

这还意味着您需要仔细构建 DockerFile，以避免缓存失效。从很少更改的操作开始，例如安装项目依赖项，然后从更频繁更改的操作结束，例如添加代码。我们示例中带注释的 Dockerfile 具有有关缓存使用情况的指示。

这也意味着图像永远不会变小，即使层删除了数据，也会添加一个新层，因为上一层仍然存储在磁盘上。如果你想从一个步骤中去除积垢，你需要在同一个步骤中完成。

Keeping your containers small is quite important. In any Docker system, the tendency is to have a bunch of containers and lots of images. Big images for no reason will fill up repositories quickly. They'll be slow to download and push, and also slow to start, as the container is copied around in your infrastructure.

There's another practical consideration. Containers are a great tool to simplify and reduce your service to the minimum. With a bit of investment, you'll have great results and keep small and to-the-point containers.

有几种方法可以使图像保持较小。除了小心不要安装额外的元素外，最主要的是创建一个安装和卸载的单一、复杂的层，以及多阶段映像。多级 DockerFile 是一种引用前一个中间层并从中复制数据的方法。检查 Docker 文档（[https://docs.docker.com/develop/develop-images/multistage-build/](https://docs.docker.com/develop/develop-images/multistage-build/) ）。

Compilers, in particular, tend to get a lot of space. When possible, try to use precompiled binaries. You can use a multi-stage Dockerfile to compile in one container and then copy the binaries to the running one.

您可以在本文中进一步了解这两种策略之间的差异：[https://pythonspeed.com/articles/smaller-python-docker-images/](https://pythonspeed.com/articles/smaller-python-docker-images/) 。

A good tool to analyze a particular image and the layers that compose it is `dive` ([https://github.com/wagoodman/dive](https://github.com/wagoodman/dive)). It will also discover ways that an image can be reduced in size.

我们将在下一步中创建一个多级容器。

# 构建 web 服务容器

我们有一个特定的目标，创建一个能够运行我们的微服务的容器，`ThoughtsBackend`。为此，我们有几个要求：

*   我们需要将代码复制到容器中。
*   代码需要通过 web 服务器提供。

因此，概括地说，我们需要创建一个带有 web 服务器的容器，添加代码，对其进行配置，使其运行代码，并在启动容器时提供结果。

We will store most of the configuration files inside subdirectories in the `./docker` directory.

作为 web 服务器，我们将使用 uWSGI（[https://uwsgi-docs.readthedocs.io/en/latest/](https://uwsgi-docs.readthedocs.io/en/latest/) ）。uWSGI 是一个 web 服务器，能够通过 WSGI 协议为我们的 Flask 应用程序提供服务。uWSGI 非常可配置，有很多选项，并且能够直接为 HTTP 服务。

A very common configuration is to have NGINX in front of uWSGI to serve static files, as it's more efficient for that. In our specific use case, we don't serve many static files, as we're running a RESTful API, and, in our main architecture, as described in [Chapter 1](01.html), *Making the Move – Design, Plan, and Execute*, there's already a load balancer on the frontend and a dedicated static files server. This means we won't be adding an extra component for simplicity. NGINX usually communicates to uWSGI using the `uwsgi` protocol, which is a protocol specifically for the uWSGI server, but it can also do it through HTTP. Check the NGINX and uWSGI documentation.

让我们看一下这个文件。它有两个阶段；第一个是编译依赖项：

```py
########
# This image will compile the dependencies
# It will install compilers and other packages, that won't be carried
# over to the runtime image
########
FROM alpine:3.9 AS compile-image

# Add requirements for python and pip
RUN apk add --update python3

RUN mkdir -p /opt/code
WORKDIR /opt/code

# Install dependencies
RUN apk add python3-dev build-base gcc linux-headers postgresql-dev libffi-dev

# Create a virtual environment for all the Python dependencies
RUN python3 -m venv /opt/venv
# Make sure we use the virtualenv:
ENV PATH="/opt/venv/bin:$PATH"
RUN pip3 install --upgrade pip

# Install and compile uwsgi
RUN pip3 install uwsgi==2.0.18
# Install other dependencies
COPY ThoughtsBackend/requirements.txt /opt/
RUN pip3 install -r /opt/requirements.txt
```

此阶段执行以下步骤：

1.  命名舞台`compile-image`，传承自阿尔卑斯山。
2.  安装`python3`。
3.  安装构建依赖项，包括`gcc`编译器和 Python 标头（`python3-dev`）。
4.  创建一个新的虚拟环境。我们将在这里安装所有 Python 依赖项。
5.  虚拟环境被激活。
6.  安装 uWSGI。这一步从代码中编译它。

You can also install the included uWSGI package in the Alpine distribution, but I found the compiled package to be more complete and easier to configure, as the Alpine `uwsgi` package requires you to install other packages such as `uwsgi-python3`, `uwsgi-http`, and so on, then enable the plugin in the uWSGI config. The size difference is minimal. This also allows you to use the latest uWSGI version and not depend on the one in your Alpine distribution.

7.  复制`requirements.txt`文件并安装所有依赖项。这将编译依赖项并将其复制到虚拟环境。

第二阶段是准备正在运行的容器。让我们来看一看：

```py
########
# This image is the runtime, will copy the dependencies from the other
########
FROM alpine:3.9 AS runtime-image

# Install python
RUN apk add --update python3 curl libffi postgresql-libs

# Copy uWSGI configuration
RUN mkdir -p /opt/uwsgi
ADD docker/app/uwsgi.ini /opt/uwsgi/
ADD docker/app/start_server.sh /opt/uwsgi/

# Create a user to run the service
RUN addgroup -S uwsgi
RUN adduser -H -D -S uwsgi
USER uwsgi

# Copy the venv with compile dependencies from the compile-image
COPY --chown=uwsgi:uwsgi --from=compile-image /opt/venv /opt/venv
# Be sure to activate the venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy the code
COPY --chown=uwsgi:uwsgi ThoughtsBackend/ /opt/code/

# Run parameters
WORKDIR /opt/code
EXPOSE 8000
CMD ["/bin/sh", "/opt/uwsgi/start_server.sh"]
```

它执行以下行动：

1.  如前所述，将图像标记为`runtime-image`并继承自 Alpine。
2.  安装 Python 和运行时的其他要求。

Note that any runtime required for compilation needs to be installed. For example, we install `libffi` in the runtime and `libffi-dev` to compile, required by the `cryptography` package. A mismatch will raise a runtime error when trying to access the (non-present) libraries. The `dev` libraries normally contain the runtime libraries.

3.  复制 uWSGI 配置和脚本以启动服务。我们马上来看看。

4.  创建一个用户来运行服务，并使用`USER`命令将其设置为默认值。

This step is not strictly necessary as, by default, the root user will be used. As our containers are isolated, gaining root access in one is inherently more secure than in a real server. In any case, it's good practice to not configure our public-facing service accessing as root and it will remove some understandable warnings.

5.  从`compile-image`映像复制虚拟环境。这将安装所有已编译的 Python 包。请注意，它们是与用户一起复制的，以运行服务并访问它们。虚拟环境已激活。
6.  复制应用程序代码。
7.  定义运行参数。注意端口`8000`是暴露的。这将是我们为应用程序提供服务的端口。

If running as root, port `80` can be defined. Routing a port in Docker is trivial, though, and other than the front-facing load balancer, there's not really any reason why you need to use the default HTTP port. Use the same one in all your systems, though, which will remove uncertainty.

请注意，应用程序代码复制在文件末尾。应用程序代码可能是更改最频繁的代码，因此此结构利用 Docker 缓存，只重新创建最后几层，而不必从头开始。在设计 DockerFile 时要考虑到这一点。

Also, keep in mind that there's nothing stopping you from changing the order while developing. If you're trying to find a problem with a dependency, and so on, you can comment out irrelevant layers or add steps later once the code is stable.

让我们现在构建容器。请注意，创建了两个图像，但只命名了一个。另一个是编译映像，它更大，因为它包含编译器，依此类推：

```py
$ docker build -f docker/app/Dockerfile --tag thoughts-backend .
...
 ---> 027569681620
Step 12/26 : FROM alpine:3.9 AS runtime-image
...
Successfully built 50efd3830a90
Successfully tagged thoughts-backend:latest
$ docker images | head
REPOSITORY TAG IMAGE ID CREATED SIZE
thoughts-backend latest 50efd3830a90 10 minutes ago 144MB
<none>           <none> 027569681620 12 minutes ago 409MB
```

现在我们可以运行容器了。为了能够访问内部端口`8000`，我们需要使用`-p`选项对其进行路由：

```py
$ docker run -it  -p 127.0.0.1:8000:8000/tcp thoughts-backend
```

访问本地浏览器`127.0.0.1`显示我们的应用程序。您可以在标准输出中看到访问日志：

![](assets/b89b7dd6-5676-4799-8613-bc8cf531e29a.png)

您可以使用`docker exec`从不同的终端访问正在运行的容器，并执行新的 shell。记住添加`-it`以保持终端打开。使用`docker ps`检查当前运行的集装箱，以查找集装箱 ID：

```py
$ docker ps
CONTAINER ID IMAGE            COMMAND ... PORTS ...
ac2659958a68 thoughts-backend ... ...     127.0.0.1:8000->8000/tcp 
$ docker exec -it ac2659958a68 /bin/sh
/opt/code $ ls
README.md __pycache__ db.sqlite3 init_db.py pytest.ini requirements.txt tests thoughts_backend wsgi.py
/opt/code $ exit
$ 
```

您可以使用*Ctrl*+*C*停止集装箱，或者更优雅地从另一个终端停止集装箱：

```py
$ docker ps
CONTAINER ID IMAGE            COMMAND ... PORTS ...
ac2659958a68 thoughts-backend ... ...     127.0.0.1:8000->8000/tcp 
$ docker stop ac2659958a68
ac2659958a68
```

日志将显示`graceful stop`：

```py
...
spawned uWSGI master process (pid: 6)
spawned uWSGI worker 1 (pid: 7, cores: 1)
spawned uWSGI http 1 (pid: 8)
Caught SIGTERM signal! Sending graceful stop to uWSGI through the master-fifo
Fri May 31 10:29:47 2019 - graceful shutdown triggered...
$ 
```

正确捕获`SIGTERM`并优雅地停止我们的服务对于避免服务突然终止非常重要。我们将看到如何在 uWSGI 中配置它，以及其他元素。

# 配置 uWSGI

`uwsgi.ini`文件包含 uWSGI 配置：

```py
[uwsgi]
uid=uwsgi
chdir=/opt/code
wsgi-file=wsgi.py
master=True
pidfile=/tmp/uwsgi.pid
http=:8000
vacuum=True
processes=1
max-requests=5000
# Used to send commands to uWSGI
master-fifo=/tmp/uwsgi-fifo
```

其中大部分是我们从 Dockerfile 获得的信息，尽管它需要匹配，以便 uWSGI 知道在哪里可以找到应用程序代码、要启动的 WSGI 文件的名称、要启动它的用户等等。

其他参数特定于 uWSGI 行为：

*   `master`：创建控制其他流程的主流程。建议用于 uWSGI 操作，因为它可以创建更平滑的操作。
*   `http`：在指定端口服务。HTTP 模式创建一个进程，该进程将负载平衡 HTTP 请求到工作进程，建议在容器外部提供 HTTP 服务。
*   `processes`：申请人数。注意，在我们的配置中，这实际上意味着三个进程：主进程、HTTP 进程和工作进程。更多的工作人员可以处理更多的请求，但将使用更多的内存。在生产中，您需要找到适合您的数字，并将其与容器的数量进行平衡。
*   `max-requests`：工作人员处理此数量的请求后，回收该工作人员（停止该工作人员并启动一个新的工作人员）。这降低了内存泄漏的可能性。
*   `vacuum`：退出时清洁环境。
*   `master-fifo`：创建 Unix 管道，向 uWSGI 发送命令。我们将使用它来处理优雅的停止。

The uWSGI documentation ([https://uwsgi-docs.readthedocs.io/en/latest/](https://uwsgi-docs.readthedocs.io/en/latest/)) is quite extensive and comprehensive. It contains a lot of valuable information, both for operating uWSGI itself and understanding details about how web servers operate. I learn something new each time that I read it, but it can be a bit overwhelming at first.

It's worth investing a bit of time in running tests to discover what are the best parameters for your service in areas such as timeouts, the number of workers, and so on. However, remember that some of the options for uWSGI may be better served with your container's configuration, which simplifies things.

为了允许优雅的停止，我们将 uWSGI 的执行包装在我们的`start_server.sh`脚本中：

```py
#!/bin/sh

_term() {
  echo "Caught SIGTERM signal! Sending graceful stop to uWSGI through the master-fifo"
  # See details in the uwsgi.ini file and
  # in http://uwsgi-docs.readthedocs.io/en/latest/MasterFIFO.html
  # q means "graceful stop"
  echo q > /tmp/uwsgi-fifo
}

trap _term SIGTERM

uwsgi --ini /opt/uwsgi/uwsgi.ini &

# We need to wait to properly catch the signal, that's why uWSGI is started
# in the background. $! is the PID of uWSGI
wait $!
# The container exits with code 143, which means "exited because SIGTERM"
# 128 + 15 (SIGTERM)
# http://www.tldp.org/LDP/abs/html/exitcodes.html
# http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_12_02.html
```

脚本的核心是调用`uwsgi`来启动服务。然后它将等待直到停止。

通过向`master-fifo`管道发送`q`命令，捕捉`SIGTERM`信号并优雅地停止 uWSGI。

A graceful stop means that a request won't be interrupted when a new container version is available. We'll see later how to make rollout deployments, but one of the key elements is to interrupt existing servers when they are not serving requests, to avoid stopping in the middle of a request and leaving an inconsistent state.

Docker 使用`SIGTERM`信号停止执行集装箱。超时后，会用`SIGKILL`杀死它们。

# 刷新 Docker 命令

我们已经了解了一些重要的 Docker 命令：

*   `docker build`：塑造形象
*   `docker run`：运行图像
*   `docker exec`：在运行的容器中执行命令
*   `docker ps`：显示当前正在运行的容器
*   `docker images`：显示现有图像

虽然这些都是基本的，但了解大多数可用的 Docker 命令对于调试问题和执行诸如监视、复制和标记图像、创建网络等操作非常有用。这些命令还将向您展示 Docker 如何在内部工作。

An important command: be sure to clean up old containers and images with `docker system prune` from time to time. Docker is quite space-intensive after working with it for a few weeks.

Docker 文档（[https://docs.docker.com/v17.12/engine/reference/commandline/docker/](https://docs.docker.com/v17.12/engine/reference/commandline/docker/) 是比较完整的。一定要知道你的方法。

# 使用不可变容器操作

DOCKER 命令，如本章前面所看到的是基础，所有的命令都是从这里开始的。但是，当处理多个问题时，处理这些问题就开始变得复杂起来。您已经看到一些命令可能会变得很长。

要在集群操作中使用容器，我们将使用`docker-compose`。这是 Docker 自己的编排工具，用于定义多容器操作。它由一个包含所有不同任务和服务的 YAML 文件定义，每个任务和服务都有足够的上下文来构建和运行它。

它允许您在此配置文件中存储每个服务的不同服务和参数，默认情况下称为`docker-compose.yaml`。这允许您协调它们并生成可复制的服务集群。

# 测试容器

我们将首先创建一个服务来运行单元测试。请记住，测试需要在容器内运行*。这将标准化它们的执行，并确保依赖关系是恒定的。*

Note that, in the creation of our container, we include all the requirements to execute the tests. There's the option to create the running container and inherit from it to add the tests and test dependencies.

This certainly creates a smaller running container but creates a situation where the testing container is not 100% exactly the same as the one in production. If the size is critical and there's a big difference, this may be an option, but be aware of the differentiation if there's a subtle bug.

我们需要在`docker-compose.yaml`文件中定义一个服务，如下所示：

```py
version: '3.7'

services:
    # Development related
    test-sqlite:
        environment:
            - PYTHONDONTWRITEBYTECODE=1
        build:
            dockerfile: docker/app/Dockerfile
            context: .
        entrypoint: pytest
        volumes:
            - ./ThoughtsBackend:/opt/code
```

本节定义了一个名为`test-sqlite`的服务。构建定义要使用的 Dockerfile 和上下文，与我们使用`docker build`命令的方式相同。`docker-compose`自动设置名称。

我们可以使用以下命令构建容器：

```py
$ docker-compose build test-sqlite
Building test-sqlite
...
Successfully built 8751a4a870d9
Successfully tagged ch3_test-sqlite:latest
```

`entrypoint`指定要运行的命令，在本例中，通过`pytest`命令运行测试。

There are some differences between the command and the `entrypoint`, which both execute a command. The most relevant ones are that `command` is easier to overwrite and `entrypoint` appends any extra arguments at the end.

要运行容器，请调用`run`命令：

```py
$ docker-compose run test-sqlite
=================== test session starts ===================
platform linux -- Python 3.6.8, pytest-4.5.0, py-1.8.0, pluggy-0.12.0 -- /opt/venv/bin/python3
cachedir: .pytest_cache
rootdir: /opt/code, inifile: pytest.ini
plugins: flask-0.14.0
collected 17 items

tests/test_thoughts.py::test_create_me_thought PASSED [ 5%]
...
tests/test_token_validation.py::test_valid_token_header PASSED [100%]

========== 17 passed, 177 warnings in 1.25 seconds ============
$ 
```

您可以附加将传递给内部`entrypoint`的`pytest`参数。例如，要运行与*验证*字符串匹配的测试，请运行以下命令：

```py
$ docker-compose run test-sqlite -k validation
...
===== 9 passed, 8 deselected, 13 warnings in 0.30 seconds =======
$
```

还有两个额外的细节：当前代码通过卷装入，并覆盖容器中的代码。查看`./ThoughtsBackend`中的当前代码如何安装在容器`/opt/code`中的代码位置。这对于开发来说非常方便，因为它将避免每次进行更改时都必须重新构建容器。

这也意味着装入的目录层次结构中的任何写入操作都将保存在本地文件系统中。例如，`./ThoughtsBackend/db.sqlite3`数据库文件允许您使用它进行测试。它还将存储生成的`pyc`文件。

The generation of the `db.sqlite3` file can create permission problems in some operating systems. If that's the case, delete it to be regenerated and/or allow it to read and write to all users with `chmod 666 ./ThoughtsBackend/db.sqlite3`.

这就是为什么我们使用`environment`选项来传递`PYTHONDONTWRITEBYTECODE=1`环境变量。这会阻止 Python 创建`pyc`文件。

虽然 SQLite 适合测试，但我们需要创建一个更好的反映部署的结构，并配置对数据库的访问，以便能够部署服务器。

# 创建 PostgreSQL 数据库容器

我们需要针对 PostgreSQL 数据库测试代码。这是我们将在生产中部署代码的数据库。

虽然 SQLAlchemy 中的抽象层旨在减少差异，但数据库的行为存在一些差异。

例如，在`/thoughts_backend/api_namespace.py`中，以下行不区分大小写，这是我们想要的行为：

```py
query = (query.filter(ThoughtModel.text.contains(search_param)))
```

将其转换为 PostgreSQL 时，它是区分大小写的，需要您进行检查。如果使用 SQLite 进行测试并在 PostgreSQL 中运行，这将是生产中的一个 bug。

The replaced code, using `ilike` for the expected behavior, is as follows:

`param = f'%{search_param}%'`
`query = (query.filter(ThoughtModel.text.ilike(param)))`

We kept the old code in a comment to show this issue.

要创建数据库容器，我们需要定义相应的 Dockerfile。我们将所有文件存储在`docker/db/`子目录中。让我们看看 DOCKFILE 及其不同的部分。整个文件可以在 GitHub（[上找到 https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter03/docker/db/Dockerfile](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter03/docker/db/Dockerfile) 。此 Dockerfile 可分为以下几个阶段：

1.  使用`ARG`关键字定义基本的 PostgreSQL 配置，如数据库名称、用户和密码。它们在环境变量中设置，以便 PostgreSQL 命令可以使用它们。

These commands are for local development only. They'll need to match with the environment set up. The `ARG` keyword defines a parameter for Dockerfile at build time. We'll see how they are set up as input parameters in the `docker-compose.yaml` file.

`ARG`元素也被定义为`ENV`变量，因此我们将它们定义为环境变量：

```py
# This Dockerfile is for localdev purposes only, so it won't be
# optimised for size
FROM alpine:3.9

# Add the proper env variables for init the db
ARG POSTGRES_DB
ENV POSTGRES_DB $POSTGRES_DB
ARG POSTGRES_USER
ENV POSTGRES_USER $POSTGRES_USER
ARG POSTGRES_PASSWORD
ENV POSTGRES_PASSWORD $POSTGRES_PASSWORD
ARG POSTGRES_PORT
ENV LANG en_US.utf8
EXPOSE $POSTGRES_PORT

# For usage in startup
ENV POSTGRES_HOST localhost
ENV DATABASE_ENGINE POSTGRESQL
# Store the data inside the container, as we don't care for
# persistence
RUN mkdir -p /opt/data
ENV PGDATA /opt/data
```

2.  安装`postgresql`包及其所有依赖项，如 Python 3 及其编译器。我们需要他们能够运行应用程序代码：

```py
RUN apk update
RUN apk add bash curl su-exec python3
RUN apk add postgresql postgresql-contrib postgresql-dev
RUN apk add python3-dev build-base linux-headers gcc libffi-dev
```

3.  安装并运行`postgres-setup.sh`脚本：

```py
# Adding our code
WORKDIR /opt/code

RUN mkdir -p /opt/code/db
# Add postgres setup
ADD ./docker/db/postgres-setup.sh /opt/code/db/
RUN /opt/code/db/postgres-setup.sh
```

这将初始化数据库，设置正确的用户、密码等。请注意，这还没有为我们的应用程序创建特定的表。

As part of our initialization, we create the data files inside the container. This means that the data won't persist after the container stops. This is a good thing for testing, but, if you want to access the data for debug purposes, remember to keep the container up.

4.  安装要在数据库容器中运行的应用程序和特定命令的要求：

```py
## Install our code to prepare the DB
ADD ./ThoughtsBackend/requirements.txt /opt/code

RUN pip3 install -r requirements.txt
```

5.  复制`docker/db`中存储的应用程序代码和数据库命令。运行`prepare_db.sh`脚本，创建应用程序数据库结构。在我们的例子中，它设置了`thoughts`表：

```py
## Need to import all the code, due dependencies to initialize the DB
ADD ./ThoughtsBackend/ /opt/code/
# Add all DB commands
ADD ./docker/db/* /opt/code/db/

## get the db ready
RUN /opt/code/db/prepare_db.sh
```

该脚本首先启动后台运行的 PostgreSQL 数据库，然后调用`init_db.py`，然后优雅地停止数据库。

Keep in mind that, in each of the steps of Dockerfile, in order to access the database, it needs to be running, but it will also be stopped at the end of each step. In order to avoid corruption of the data or the abrupt killing of the process, be sure to use the `stop_postgres.sh` script until the end. Though PostgreSQL will normally recover for an abruptly stopped database, it will slow the startup time.

6.  要启动运行中的数据库，CMD 只是`postgres`命令。需要与`postgres`用户一起运行：

```py
# Start the database in normal operation
USER postgres
CMD ["postgres"]
```

要运行数据库服务，我们需要将其设置为`docker-compose`文件的一部分：

```py
    db:
        build:
            context: .
            dockerfile: ./docker/db/Dockerfile
            args:
                # These values should be in sync with environment
                # for development. If you change them, you'll 
                # need to rebuild the container
                - POSTGRES_DB=thoughts
                - POSTGRES_USER=postgres
                - POSTGRES_PASSWORD=somepassword
                - POSTGRES_PORT=5432
        ports:
            - "5432:5432"
```

注意，`args`参数将在构建期间设置`ARG`值。我们还路由 PostgreSQL 端口以允许访问数据库。

现在，您可以构建并启动服务器：

```py
$ docker-compose up build
$ docker-compose up db
Creating ch3_db_1 ... done
Attaching to ch3_db_1
...
db_1 | 2019-06-02 13:55:38.934 UTC [1] LOG: database system is ready to accept connections
```

在另一个终端中，可以使用 PostgreSQL 客户端访问数据库。我推荐神奇的`pgcli`。您可以查看其文档（[https://www.pgcli.com/](https://www.pgcli.com/) 。

You can use also the official `psql` client or any other PostgreSQL client of your preference. The documentation for the default client can be found here: [https://www.postgresql.org/docs/current/app-psql.html](https://www.postgresql.org/docs/current/app-psql.html).

这里，我们使用`PGPASSWORD`环境变量来显示密码是之前配置的密码：

```py
$ PGPASSWORD=somepassword pgcli -h localhost -U postgres thoughts
Server: PostgreSQL 11.3
Version: 2.0.2
Chat: https://gitter.im/dbcli/pgcli
Mail: https://groups.google.com/forum/#!forum/pgcli
Home: http://pgcli.com
postgres@localhost:thoughts> select * from thought_model
+------+------------+--------+-------------+
|  id  |  username  |  text  |  timestamp  |
|------+------------+--------+-------------|
+------+------------+--------+-------------+
SELECT 0
Time: 0.016s
```

能够访问数据库对于调试非常有用。

# 配置您的服务

我们可以将服务配置为使用环境变量来更改行为。对于容器来说，这是使用配置文件的一个极好的替代方案，因为它允许注入配置的不可变容器。这与十二因素应用程序（[一致 https://12factor.net/config](https://12factor.net/config) ）原则，允许代码和配置之间的良好分离，以及设置代码可能用于的不同部署。

One of the advantages that we'll look at later with the use of Kubernetes is creating new environments on-demand, which can be tweaked for testing purposes or tailored for development or demo. Being able to quickly change all the configuration by injecting the proper environment makes this operation very easy and straightforward. It also allows you to enable or disable features, if properly configured, which helps the enablement of features on launch day, with no code rollout.

这允许连接数据库的配置，因此我们可以在 SQLite 后端或 PostgreSQL 之间进行选择。

Configuring the system is not limited to open variables, though. Environment variables will be used later in the book for storing secrets. Note that a secret needs to be available inside the container.

我们将配置测试以访问新创建的数据库容器。为此，我们首先需要能够通过配置在 SQLite 或 PostgreSQL 之间进行选择。查看`./ThoughtsBackend/thoughts_backend/db.py`文件：

```py
import os
from pathlib import Path
from flask_sqlalchemy import SQLAlchemy

DATABASE_ENGINE = os.environ.get('DATABASE_ENGINE', 'SQLITE')

if DATABASE_ENGINE == 'SQLITE':
    dir_path = Path(os.path.dirname(os.path.realpath(__file__)))
    path = dir_path / '..'

    # Database initialisation
    FILE_PATH = f'{path}/db.sqlite3'
    DB_URI = 'sqlite+pysqlite:///{file_path}'
    db_config = {
        'SQLALCHEMY_DATABASE_URI': DB_URI.format(file_path=FILE_PATH),
        'SQLALCHEMY_TRACK_MODIFICATIONS': False,
    }

elif DATABASE_ENGINE == 'POSTGRESQL':
    db_params = {
        'host': os.environ['POSTGRES_HOST'],
        'database': os.environ['POSTGRES_DB'],
        'user': os.environ['POSTGRES_USER'],
        'pwd': os.environ['POSTGRES_PASSWORD'],
        'port': os.environ['POSTGRES_PORT'],
    }
    DB_URI = 'postgresql://{user}:{pwd}@{host}:{port}/{database}'
    db_config = {
        'SQLALCHEMY_DATABASE_URI': DB_URI.format(**db_params),
        'SQLALCHEMY_TRACK_MODIFICATIONS': False,
    }

else:
    raise Exception('Incorrect DATABASE_ENGINE')

db = SQLAlchemy()
```

当使用设置为`POSTGRESQL`的`DATABASE_ENGINE`环境变量时，会对其进行正确配置。其他环境变量需要正确；也就是说，如果数据库引擎设置为 PostgreSQL，则需要设置`POSTGRES_HOST`变量。

环境变量可以单独存储在`docker-compose.yaml`文件中，但在一个文件中存储多个更方便。让我们来看一看：

```py
DATABASE_ENGINE=POSTGRESQL
POSTGRES_DB=thoughts
POSTGRES_USER=postgres
POSTGRES_PASSWORD=somepassword
POSTGRES_PORT=5432
POSTGRES_HOST=db
```

请注意，用户等的定义与为测试创建 Dockerfile 的参数一致。`POSTGRES_HOST`定义为`db`，是服务的名称。

Inside the Docker cluster created for `docker-compose`, you can refer to services by their names. This will be directed by the internal DNS to the proper container, as a shortcut. This allows easy communication between services, as they can configure their access very easily by name. Note that this connection is only valid inside the cluster, for communication between containers.

我们使用 PostgreSQL 容器的测试服务的定义如下：

```py
    test-postgresql:
        env_file: environment.env
        environment:
            - PYTHONDONTWRITEBYTECODE=1
        build:
            dockerfile: docker/app/Dockerfile
            context: .
        entrypoint: pytest
        depends_on:
            - db
        volumes:
            - ./ThoughtsBackend:/opt/code
```

这与`test-sqlite`服务非常相似，但它在`environment.env`中增加了环境配置，并增加了对`db`的依赖。这意味着`docker-compose`将启动`db`服务（如果不存在）。

现在可以对 PostgreSQL 数据库运行测试：

```py
$ docker-compose run test-postgresql
Starting ch3_db_1 ... done
============== test session starts ====================
platform linux -- Python 3.6.8, pytest-4.6.0, py-1.8.0, pluggy-0.12.0 -- /opt/venv/bin/python3
cachedir: .pytest_cache
rootdir: /opt/code, inifile: pytest.ini
plugins: flask-0.14.0
collected 17 items

tests/test_thoughts.py::test_create_me_thought PASSED [ 5%]
...
tests/test_token_validation.py::test_valid_token_header PASSED [100%]

===== 17 passed, 177 warnings in 2.14 seconds ===
$
```

此环境文件对于需要连接到数据库的任何服务都很有用，例如在本地部署服务。

# 在本地部署 Docker 服务

使用所有这些元素，我们可以创建服务以在本地部署 Thinks 服务：

```py
     server:
        env_file: environment.env
        image: thoughts_server
        build:
            context: .
            dockerfile: docker/app/Dockerfile
        ports:
            - "8000:8000"
        depends_on:
            - db
```

我们需要确保添加`db`数据库服务的依赖项。我们还绑定了内部端口，以便可以在本地访问它。

We start the service with the `up` command. There are some differences between the `up` and the `run` commands, but the main one is that `run` is for single commands that start and stop, while `up` is designed for services. For example, `run` creates an interactive Terminal, which displays colors, and `up` shows the standard output as logs, including the time when they were generated, accepts the `-d` flag to run in the background, and so on. Using one instead of the other is normally okay, however, `up` exposes ports and allows other containers and services to connect, while `run` does not.

我们现在可以使用以下命令启动服务：

```py
$ docker-compose up server
Creating network "ch3_default" with the default driver
Creating ch3_db_1 ... done
Creating ch3_server_1 ... done
Attaching to ch3_server_1
server_1 | [uWSGI] getting INI configuration from /opt/uwsgi/uwsgi.ini
server_1 | *** Starting uWSGI 2.0.18 (64bit) on [Sun Jun 2 
...
server_1 | spawned uWSGI master process (pid: 6)
server_1 | spawned uWSGI worker 1 (pid: 7, cores: 1)
server_1 | spawned uWSGI http 1 (pid: 8)
```

现在通过浏览器访问`localhost:8000`中的服务：

![](assets/741100a2-4db5-4976-9d76-557fb89dcdaf.png)

您可以在终端中看到日志。点击*Ctrl*+*C*将停止服务器。也可以使用`-d`标志启动服务，以分离终端并在守护程序模式下运行：

```py
$ docker-compose up -d server
Creating network "ch3_default" with the default driver
Creating ch3_db_1 ... done
Creating ch3_server_1 ... done
$
```

使用`docker-compose ps`检查正在运行的服务及其当前状态，并打开端口：

```py
$ docker-compose ps
 Name Command State Ports
------------------------------------------------------------------------------
ch3_db_1 postgres Up 0.0.0.0:5432->5432/tcp
ch3_server_1 /bin/sh /opt/uwsgi/start_s ... Up 0.0.0.0:8000->8000/tcp
```

如前所述，我们可以直接访问数据库并在其中运行原始 SQL 命令。这对于调试问题或进行实验非常有用：

```py
$ PGPASSWORD=somepassword pgcli -h localhost -U postgres thoughts
Server: PostgreSQL 11.3
Version: 2.0.2

postgres@localhost:thoughts> 
INSERT INTO thought_model (username, text, timestamp) 
VALUES ('peterparker', 'A great power carries a great
 responsability', now());

INSERT 0 1
Time: 0.014s
postgres@localhost:thoughts>
```

现在，可通过以下 API 获得该思想：

```py
$ curl http://localhost:8000/api/thoughts/
[{"id": 1, "username": "peterparker", "text": "A great power carries a great responsability", "timestamp": "2019-06-02T19:44:34.384178"}]
```

如果需要在分离模式下查看日志，可以使用`docker-compose logs <optional: service>`命令：

```py
$ docker-compose logs server
Attaching to ch3_server_1
server_1 | [uWSGI] getting INI configuration from /opt/uwsgi/uwsgi.ini
server_1 | *** Starting uWSGI 2.0.18 (64bit) on [Sun Jun 2 19:44:15 2019] ***
server_1 | compiled with version: 8.3.0 on 02 June 2019 11:00:48
...
server_1 | [pid: 7|app: 0|req: 2/2] 172.27.0.1 () {28 vars in 321 bytes} [Sun Jun 2 19:44:41 2019] GET /api/thoughts/ => generated 138 bytes in 4 msecs (HTTP/1.1 200) 2 headers in 72 bytes (1 switches on core 0)
```

要完全停止集群，请调用`docker-compose down`：

```py
$ docker-compose down
Stopping ch3_server_1 ... done
Stopping ch3_db_1 ... done
Removing ch3_server_1 ... done
Removing ch3_db_1 ... done
Removing network ch3_default
```

这将停止所有容器。

# 将 Docker 映像推送到远程注册表

我们看到的所有操作都与本地 Docker 存储库一起工作。考虑到 Docker 图像的结构和每个层都可以独立工作的事实，它们很容易上传和共享。为此，我们需要使用远程存储库，或者 Docker 术语中的注册表，它将接受推送到它的图像，并允许从中提取图像。

The structure of a Docker image is composed of each of the layers. Each of them can be pushed independently, as long as the registry contains the layer it depends on. This saves space if the previous layers are already present, as they will be stored only once.

# 从 Docker Hub 获取公共图像

默认注册表是 Docker Hub。这是默认配置的，它是公共映像的主要来源。您可以在[中自由访问 https://hub.docker.com/](https://hub.docker.com/) 并搜索可用图像，以将图像建立在以下基础上：

![](assets/11179995-9c90-434a-9807-c307bd277d53.png)

每个图像都有关于使用方法和可用标记的信息。您无需单独下载图像，只需使用图像名称或运行`docker pull`命令即可。如果未指定其他注册表，Docker 将自动从 Docker Hub 中提取：

![](assets/fa6ae25c-9a50-42dc-88be-d66941b5743f.png)

图像的名称也是我们在 Dockerfiles 中的`FROM`命令中使用的名称。

Docker is a fantastic way of distributing a tool. It's very common right now for an open source tool to have an official image in Docker Hub that can be downloaded and started in a standalone model, standardizing the access.

This can be used either for a quick demo, for something such as Ghost—[https://hub.docker.com/_/ghost](https://hub.docker.com/_/ghost) (a blogging platform), or a Redis ([https://hub.docker.com/_/redis](https://hub.docker.com/_/redis)) instance to act as cache with minimal work. Try to run the Ghost example locally.

# 使用标签

标签是描述符，用于标记同一图像的不同版本。有一个图像`alpine:3.9`，还有一个图像`alpine:3.8`。对于不同的解释器（3.6、3.7、2.7 等等），也有 Python 的官方图像，但是除了版本之外，解释器可能会参考图像的创建方式。

例如，这些图像具有相同的效果。第一个是包含 Python 3.7 解释器的完整图像：

```py
$ docker run -it python:3.7
Python 3.7.3 (default, May 8 2019, 05:28:42)
[GCC 6.3.0 20170516] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

第二个也有一个 Python 3.7 解释器。注意`slim`名称的变化：

```py
$ docker run -it python:3.7-slim
Python 3.7.3 (default, May 8 2019, 05:31:59)
[GCC 6.3.0 20170516] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

但是，图像的大小却大不相同：

```py
$ docker images | grep python
python 3.7-slim ca7f9e245002 4 weeks ago 143MB
python 3.7      a4cc999cf2aa 4 weeks ago 929MB
```

如果没有指定另一个标记，任何构建都会自动使用`latest`标记。

Keep in mind that tags can be overwritten. This may be confusing, given some of the similarities between the way Docker and Git work, as the term "tag" in Git means something that can't change. A tag in Docker is similar to a branch in Git.

单个图像可以使用不同的标记进行多次标记。例如，`latest`标签也可以是版本`v1.5`：

```py
$ docker tag thoughts-backend:latest thoughts-backend:v1.5
$ docker images
REPOSITORY       TAG    IMAGE ID     CREATED    SIZE
thoughts-backend latest c7a8499623e7 5 min ago 144MB
thoughts-backend v1.5   c7a8499623e7 5 min ago 144MB
```

注意`image id`是如何相同的。使用标记可以标记特定的图像，这样我们就知道它们已经准备好部署或赋予它们某种意义。

# 进入注册表

一旦我们对图像进行了标记，我们就可以将其推送到共享注册表，以便其他服务可以使用它。

可以部署自己的 Docker 注册表，但是，除非严格必要，否则最好避免使用它。有云提供商允许您创建自己的注册表，无论是公共的还是私有的，甚至在您自己的私有云网络中。如果你想让你的图像可用，最好的选择是 Docker Hub，因为它是标准的，而且最容易访问。在本章中，我们将在这里创建一个，但我们将在本书后面探讨其他选项。

It's worth saying it again: maintaining your own Docker registry is much more expensive than using a provider one. Commercial prices for registries, unless you require a lot of repos will be in the range of tens of dollars per month, and there are options from well-known cloud providers such as AWS, Azure, and Google Cloud.

除非您确实需要，否则请避免使用您自己的注册表。

我们将在 Docker Hub 注册表中创建新的回购协议。你可以免费创建私人回购协议，也可以创建任意数量的公共回购协议。您需要创建一个新用户，下载 Docker 时可能就是这样。

A repo, in Docker terms, is a set of images with different tags; for example, all the tags of `thoughts-backend`. This is different from the registry, which is a server that contains several repos.

在更非正式的术语中，通常将登记处称为*回购*，将回购称为*图像*，不过，单纯地说，图像是唯一的，可能是标签（也可能不是）。

然后，您可以创建一个新的回购协议，如下所示：

![](assets/d617ceee-0f7b-451a-9bc8-affb75606f9a.png)

一旦创建了回购协议，我们需要相应地标记我们的图像。这意味着它应该在 Docker Hub 中包含用户名以识别回购协议。另一种方法是使用包含的用户名直接命名图像：

```py
$ docker tag thoughts-backend:latest jaimebuelta/thoughts-backend:latest
```

为了能够访问回购协议，我们需要在 Docker Hub 中使用用户名和密码登录 Docker：

```py
$ docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: jaimebuelta
Password:
Login Succeeded
```

登录后，您可以推送图像：

```py
$ docker push jaimebuelta/thoughts-backend:latest
The push refers to repository [docker.io/jaimebuelta/thoughts-backend]
1ebb4000a299: Pushed
669047e32cec: Pushed
6f7246363f55: Pushed
ac1d27280799: Pushed
c43bb774a4bb: Pushed
992e49acee35: Pushed
11c1b6dd59b3: Pushed
7113f6aae2a4: Pushed
5275897866cf: Pushed
bcf2f368fe23: Mounted from library/alpine
latest: digest: sha256:f1463646b5a8dec3531842354d643f3d5d62a15cc658ac4a2bdbc2ecaf6bb145 size: 2404
```

如果本地 Docker 已正确记录，您现在可以共享该图像并从任何位置提取它。当我们部署一个生产集群时，我们需要确保执行它的 Docker 服务器能够访问注册表，并且它被正确地记录。

# 总结

在本章中，我们学习了如何使用 Docker 命令创建和操作容器。我们学习了大多数常用的 Docker 命令，例如`build`、`run`、`exec`、`ps`、`images`、`tag`和`push`。

我们了解了如何构建 web 服务容器，包括配置文件的准备、如何构造 Dockerfile 以及如何使图像尽可能小。我们还介绍了如何使用`docker-compose`在本地操作，并通过`docker-compose.yaml`文件连接在集群配置中运行的不同容器。这包括创建一个数据库容器，该容器允许使用相同的工具进行更接近生产部署的测试。

我们看到了如何使用环境变量来配置我们的服务，以及如何通过`docker-compose`配置注入它们以允许不同的模式，例如测试。

最后，我们分析了如何使用注册表来共享我们的映像，以及如何对它们进行适当的标记，并允许将它们从本地开发中移出，以便在部署中使用。

在下一章中，我们将看到如何利用创建的容器和操作自动运行测试，并使自动化工具为我们完成繁重的工作，以确保我们的代码始终是高质量的！

# 问题

1.  `FROM`关键字在 Dockerfile 中起什么作用？
2.  如何使用预定义的命令启动容器？
3.  为什么创建删除 Dockerfile 中文件的步骤不会使图像变小？
4.  你能描述一下多级 Docker 构建是如何工作的吗？
5.  `run`和`exec`命令之间有什么区别？
6.  在使用`run`和`exec`命令时，我们应该何时使用`-it`标志？
7.  您知道 uWSGI 的任何替代方案来服务 Python web 应用程序吗？
8.  `docker-compose`是用来做什么的？
9.  你能描述一下 Docker 标签是什么吗？
10.  为什么需要将图像推送到远程注册表？

# 进一步阅读

为了进一步了解 Docker 和容器，您可以查阅*精通 Docker–第三版*书籍（[https://www.packtpub.com/eu/virtualization-and-cloud/mastering-docker-third-edition](https://www.packtpub.com/eu/virtualization-and-cloud/mastering-docker-third-edition) ）。有关调整容器和学习如何提高应用程序性能的信息，请参阅*Docker 高性能-第二版*（[https://www.packtpub.com/eu/networking-and-servers/docker-high-performance-second-edition](https://www.packtpub.com/eu/networking-and-servers/docker-high-performance-second-edition) ），它涵盖了许多分析和发现性能问题的技术。