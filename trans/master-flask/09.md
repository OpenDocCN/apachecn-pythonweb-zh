# 第 9 章：用芹菜创建异步任务

在创建 web 应用程序时，将处理请求所需的时间保持在 50 毫秒以下或 50 毫秒左右至关重要。因为大部分响应时间都被等待用户连接所占用，额外的处理时间可能会使服务器挂起。应该避免在服务器上进行任何可以避免的额外处理。然而，web 应用程序中的多个操作花费的时间超过几秒钟是很常见的，特别是当涉及复杂的数据库操作或图像处理时。为了保存我们的用户体验，将使用名为芹菜的任务队列将这些操作移出 Flask 进程。

# 什么是芹菜？

**芹菜**是用 Python 编写的异步任务队列。Cellery 同时运行任务，这些任务是用户定义的函数*——通过 Python 多处理库一次运行多个任务。芹菜从**代理**接收消息，通知其启动任务，该代理通常称为消息队列，如下图所示：*

 *![What is Celery?](images/B03929_09_01.jpg)

**消息队列**是专门设计用于在生产者进程和消费者进程之间发送数据的系统。**生产者进程**是创建要在队列中发送的消息的任何程序，而**消费者进程**是将消息移出队列的任何程序。从生产者发送的消息存储在一个**先进先出**（**FIFO**队列中，在此队列中首先检索最早的项目。消息将一直存储，直到消费者收到消息，然后将其删除。消息队列提供不依赖轮询的实时消息传递，持续检查进程状态的流程。当消息从生产者发送时，消费者正在*监听*连接到消息队列的新消息；消费者没有经常联系队列。这种差异就像**AJAX**和**WebSocket**之间的差异一样；AJAX 需要与服务器不断联系，而 WebSocket只是一个连续的流。

可以用传统数据库替换消息队列。芹菜甚至内置了对 SQLAlchemy 的支持来实现这一点。然而，使用数据库作为芹菜的代理是非常不鼓励的。使用数据库代替消息队列需要使用者不断轮询数据库以获取更新。此外，由于芹菜使用多处理来实现并发性，因此进行大量读取的连接数量会迅速增加。在中等负载下，使用数据库需要生产者在使用者读取的同时对数据库进行大量写入。数据库不能有太多的连接同时对同一数据进行读取、写入和更新。发生这种情况时，表通常会被锁定，所有其他连接都会等待每次写入完成，然后才能读取数据，反之亦然。更糟糕的是，它可能导致竞争条件，即并发事件更改并读取相同的资源，并且每个并发操作都使用过时的数据版本启动。具体到芹菜，这可能导致同一操作针对同一消息运行多次。

还可以使用消息队列作为代理和数据库来存储任务的结果。在上图中，消息队列用于发送任务请求和任务结果。

但是，使用数据库存储任务的最终结果允许无限期地存储最终产品，而消息队列将在生产者收到数据后立即抛出数据，如下图所示：

![What is Celery?](images/B03929_09_02.jpg)

这个数据库通常是 NoSQL 存储的一个键值，用于帮助处理负载。如果您计划对以前运行的任务进行分析，这将非常有用；否则，只使用消息队列更安全。

甚至可以选择完全删除任务的结果，而不返回任务的结果。这样做的缺点是，制作人无法知道任务是否成功，但通常在较小的项目中，这就足够了。

对于我们的堆栈，我们将使用**RabbitMQ**作为消息代理。RabbitMQ 在所有主要操作系统上运行，设置和运行非常简单。芹菜还支持 RabbitMQ，不需要任何额外的库，是芹菜文档中推荐的消息队列。

### 注

在编写本文时，在 Python3 中无法将 RabbitMQ 与芹菜一起使用。您可以使用 Redis 而不是 RabbitMQ。唯一的区别是连接字符串。更多信息请参见[http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html](http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html) 。

# 设置芹菜和兔肉

要安装带有`pip`的芹菜，请运行以下操作：

```
$ pip install Celery

```

我们还需要一个烧瓶扩展来帮助处理芹菜：

```
$ pip install Flask-Celery-Helper

```

烧瓶文件规定，不需要为芹菜扩展烧瓶。然而，当应用程序由应用程序工厂组织时，让芹菜服务器与 Flask 的应用程序上下文协同工作是非常重要的。因此，我们将使用**摇瓶芹菜助手**来进行重物搬运。

接下来，需要安装 RabbitMQ。RabbitMQ 不是用 Python 编写的；因此，每个操作系统的安装说明都会有所不同。谢天谢地，RabbitMQ 在[为每个操作系统维护了一份详细的指令清单https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html) 。

安装 RabbitMQ 后，转到终端窗口并运行以下操作：

```
$ rabbitmq-server

```

这将使用 guest 用户和 guest 密码启动 RabbitMQ 服务器。默认情况下，RabbitMQ 只接受本地主机上的连接，因此此设置适合开发。

# 在芹菜中创建任务

正如前面提到的，芹菜任务只是执行某些操作的用户定义函数。但在编写任何任务之前，需要创建芹菜对象。这是芹菜服务器将导入的对象，用于处理运行和调度所有任务。

芹菜至少需要一个配置变量来运行：到 MessageBroker 的连接。该连接的定义类似于 SQLAlchemy 连接，即 URL。存储任务结果的后端也定义为 URL，如以下代码所示：

```
class DevConfig(Config):
    DEBUG = True
    SQLALCHEMY_DATABASE_URI = 'sqlite:///../database.db'
    CELERY_BROKER_URL = "amqp://guest:guest@localhost:5672//"
    CELERY_BACKEND = "amqp://guest:guest@localhost:5672//"
In the extensions.py file, the Celery class from Flask-Celery-Helper will be initialized:
```

```
from flask.ext.celery import Celery
celery = Celery()
```

因此，为了使芹菜进程能够与数据库和任何其他烧瓶扩展一起工作，它需要在我们的应用程序上下文中工作。为了做到这一点，芹菜将需要为每个进程创建一个新的应用程序实例。与大多数芹菜应用程序不同，我们需要芹菜工厂来创建应用程序实例并在其上注册芹菜实例。在顶层目录中的新文件中，`manage.py`所在的相同位置，名为`celery_runner.py`，添加以下内容：

```
import os
from webapp import create_app
from celery import Celery
from webapp.tasks import log

def make_celery(app):
    celery = Celery(
        app.import_name,
        broker=app.config['CELERY_BROKER_URL'],
        backend=app.config['CELERY_BACKEND_URL']
    )
    celery.conf.update(app.config)
    TaskBase = celery.Task

    class ContextTask(TaskBase):
        abstract = True

        def __call__(self, *args, **kwargs):
            with app.app_context():
                return TaskBase.__call__(self, *args, **kwargs)

    celery.Task = ContextTask

    return celery

env = os.environ.get('WEBAPP_ENV', 'dev')
flask_app = create_app(
    'webapp.config.%sConfig' % env.capitalize()
)
celery = make_celery(flask_app)
```

`make_celery`函数的作用是将对每个芹菜任务的每个调用包装在 Python`with`块中。这确保了对任何 Flask 分机的每次调用都能在我们的应用程序中正常工作。另外，请确保不要将 Flask 应用程序实例命名为`app`，因为芹菜尝试将任何名为`app`或`celery`的对象导入为芹菜应用程序实例。因此，将烧瓶对象命名为`app`将导致芹菜尝试将其用作芹菜对象。

现在，我们可以编写第一个任务了。这将是一个简单的任务开始，一个只返回任何字符串传递给它。在名为`tasks.py`的应用程序目录中的新文件中，添加以下内容：

```
from webapp.extensions import celeryfrom webapp.extensions import celery
@celery.task()
def log(msg):
    return msg
```

现在，拼图的最后一块是在新的终端窗口中运行芹菜流程，称为**工作者**。同样，这个过程将监听我们的 message broker 以获取启动新任务的命令：

```
$ celery worker -A celery_runner --loglevel=info

```

`loglevel`标志在那里，因此您可以在终端窗口中看到任务已收到且其输出可用的确认。

现在，我们可以向芹菜工人发送命令。打开`manage.py`shell，导入`log`任务：

```
>>> from webapp.tasks import log
>>> log("Message")
Message
>>> result = log.delay("Message")

```

可以像调用任何其他函数一样调用该函数；这样做将在当前进程中执行该函数。但是，对任务调用`delay`方法将向辅助进程发送一条消息，以使用给定参数执行函数。

在运行芹菜工人的终端窗口中，您应该看到如下内容：

```
Task tasks.log succeeded in 0.0005873600021s: 'Message'

```

对于任何异步任务，`ready`方法可用于判断任务是否已成功完成。如果为 true，则可以使用`get`方法检索任务的结果。

```
>>> result.ready()
True
>>> result.get()
"Message"

```

`get`方法使当前进程等待`ready`函数返回`True`来检索结果。因此，在调用任务后立即调用`get`本质上使任务同步。因此，任务实际上很少向生产者返回值。绝大多数任务执行一些操作，然后退出。

在芹菜工人上运行任务时，可以通过`state`属性访问该任务的状态。这允许更细粒度地理解任务当前在工作进程中执行的操作。可用状态如下：

*   `FAILURE`：任务失败，所有重试也失败
*   `PENDING`：工作人员尚未收到任务
*   `RECEIVED`：工作人员已收到任务，尚未处理
*   `RETRY`：任务失败，正在等待重试
*   `REVOKED`：任务已停止
*   `STARTED`：工作人员已开始处理任务
*   `SUCCESS`：任务成功完成

在芹菜中，如果任务失败，那么任务可以通过`retry`方法调用自己，如下所示：

```
@celery.task(bind=True)
def task(self, param):
    try:
        some_code
    except Exception, e:
        self.retry(exc=e)
```

decorator 函数中的`bind`参数告诉芹菜将对任务对象的引用作为函数中的第一个参数传递。使用`self`参数，可以调用`retry`方法，该方法将使用相同的参数重新运行任务。还有几个其他参数可以传递给函数装饰器以更改任务的行为：

*   `max_retries`：这是任务在声明为失败之前可以重试的最大次数。
*   `default_retry_delay`：这是再次运行任务之前等待的时间（以秒为单位）。如果您认为导致任务失败的条件是暂时的，例如网络错误，那么最好将其保持在大约一分钟左右。
*   `rate_limit`：指定允许在给定间隔内运行的对此任务的唯一调用的总数。如果该值为整数，则表示每秒允许运行的任务总数。对于每分钟*x*任务数或*x*小时任务数，该值也可以是*x/m*形式的字符串。例如，传入*5/m*将只允许每分钟调用此任务五次。
*   `time_limit`：如果指定，则任务运行时间超过此秒数将被终止。
*   `ignore_result`：如果任务的返回值未被使用，则不返回。

最好为每个任务指定所有这些，以避免任务无法运行。

# 运行芹菜任务

`delay`方法是`apply_async`方法的速记版本，按以下格式调用：

```
task.apply_async(
    args=[1, 2],
    kwargs={'kwarg1': '1', 'kwarg2': '2'}
)
```

但是，`args`关键字可以是隐式的：

```
apply_async([1, 2], kwargs={'kwarg1': '1', 'kwarg2': '2'})
```

调用`apply_async`允许您在任务调用中定义一些在`delay`方法中无法指定的额外功能。首先，`countdown`选项指定工作人员在收到任务后应等待运行该任务的时间（以秒为单位）：

```
>>> from webapp.tasks import log
>>> log.apply_async(["Message"], countdown=600)

```

`countdown`不能保证任务在`600`秒后运行。`countdown`只表示任务在*x*秒数后开始处理。若所有工作进程都忙于其他任务，那个么它将不会立即运行。

`apply_async`给出的另一个关键字参数是`eta`参数。`eta`通过一个Python`datetime`对象传递，该对象指定任务应该在什么时候运行。同样，`eta`不可靠。

```
>>> import datetime
>>> from webapp.tasks import log
# Run the task one hour from now
>>> eta = datetime.datetime.now() + datetime.timedelta(hours=1)
>>> log.apply_async(["Message"], eta=eta)

```

## 芹菜

芹菜提供了多种方法将多个相关任务分组在一起或并行执行多个任务。这些方法受到函数式编程语言中的语言特性的很大影响。然而，要理解这是如何工作的，我们首先需要理解签名。考虑以下任务：

```
@celery.task()
def multiply(x, y):
    return x * y
```

让我们看看动作中的**签名**来理解它。打开`manage.py`外壳：

```
>>> from celery import signature
>>> from webapp.tasks import multiply
# Takes the same keyword args as apply_async
>>> signature('webapp.tasks.multiply', args=(4, 4) , countdown=10)
webapp.tasks.multiply(4, 4)
# same as above
>>> from webapp.tasks import multiply
>>> multiply.subtask((4, 4), countdown=10)
webapp.tasks.multiply(4, 4)
# shorthand for above, like delay in that it doesn't take
# apply_async's keyword args
>>> multiply.s(4, 4)
webapp.tasks.multiply(4, 4)
>>> multiply.s(4, 4)()
16
>>> multiply.s(4, 4).delay()

```

调用任务的签名，或有时调用任务的**子任务**，将创建一个可以传递给要执行的其他函数的函数。执行签名，就像示例中从第三行到最后一行一样，在当前进程而不是工作进程中执行函数。

### 部分

任务签名的第一个应用是函数式编程风格的部分。**Partials**是最初接受许多参数的函数；但是，对原始函数应用一个操作以返回一个新函数，因此第一个*n*参数始终相同。例如，`multiply`函数不是任务：

```
>>> new_multiply = multiply(2)
>>> new_multiply(5)
10
# The first function is unaffected
>>> multiply(2, 2)
4

```

这是一个虚构的 API，但它非常接近芹菜版本：

```
>>> partial = multiply.s(4)
>>> partial.delay(4)

```

worker 窗口中的输出应显示**16**。基本上，我们创建了一个新函数，它被保存为 partial，并且总是将其输入乘以 4。

### 回调

一个任务完成后，根据之前任务的输出运行另一个任务是很常见的。为此，`apply_async`函数有一个`link`方法：

```
>>> multiply.apply_async((4, 4), link=log.s())

```

工人输出应显示`multiply`任务和`log`任务返回**16**。

如果您有一个不接受输入的函数，或者您的回调不需要原始方法的结果，则必须使用`si`方法将任务签名标记为不可变：

```
>>> multiply.apply_async((4, 4), link=log.si("Message"))

```

**回调**可用于解决实际问题。如果我们希望在每次任务创建新用户时发送一封欢迎电子邮件，那么我们可以通过以下调用产生这种效果：

```
>>> create_user.apply_async(("John Doe", password), link=welcome.s())

```

分部和回调可以结合起来产生一些强大的效果：

```
>>> multiply.apply_async((4, 4), link=multiply.s(4))

```

需要注意的是，如果保存此调用并对其调用`get`方法，结果将是**16**而不是**64**。这是因为`get`方法不会返回回调方法的结果。这将通过以后的方法解决。

### 组

`group`函数获取签名列表，并创建可调用函数并行执行所有签名，然后返回所有结果列表：

```
>>> from celery import group
>>> sig = group(multiply.s(i, i+5) for i in range(10))
>>> result = sig.delay()
>>> result.get()
[0, 6, 14, 24, 36, 50, 66, 84, 104, 126]

```

### 链条

`chain`函数获取任务签名，并将每个结果的值传递给链中的下一个值，返回一个结果，如下所示：

```
>>> from celery import chain
>>> sig = chain(multiply.s(10, 10), multiply.s(4), multiply.s(20))
# same as above
>>> sig = (multiply.s(10, 10) | multiply.s(4) | multiply.s(20))
>>> result = sig.delay()
>>> result.get()
8000

```

链和部分可以再进一步。使用分部时，可以使用链来创建新函数，并且可以按如下方式嵌套链：

```
# combining partials in chains
>>> func = (multiply.s(10) | multiply.s(2))
>>> result = func.delay(16)
>>> result.get()
200
# chains can be nested
>>> func = (
 multiply.s(10) | multiply.s(2) | (multiply.s(4) | multiply.s(5))
)
>>> result = func.delay(16)
>>> result.get()
800

```

### 和弦

`chord`函数创建一个签名，该签名将执行一个`group`签名，并将最终结果传递给回调：

```
>>> from celery import chord
>>> sig = chord(
 group(multiply.s(i, i+5) for i in range(10)),
 log.s()
)
>>> result = sig.delay()
>>> result.get()
[0, 6, 14, 24, 36, 50, 66, 84, 104, 126]

```

与 link 参数一样，`get`方法不会返回回调。

将`chain`语法用于组和回调会自动创建和弦签名：

```
# same as above
>>> sig = (group(multiply.s(i, i+5) for i in range(10)) | log.s())
>>> result = sig.delay()
>>> result.get()
[0, 6, 14, 24, 36, 50, 66, 84, 104, 126]

```

### 定期运行任务

芹菜还可以定期调用任务。对于那些熟悉***nix**操作系统的用户来说，该系统非常类似于命令行实用程序`cron`，但它还有一个额外的好处，即在我们的源代码中定义，而不是在某些系统文件中定义。因此，在[第 13 章](13.html "Chapter 13. Deploying Flask Apps")、*部署 Flask 应用程序*中，当我们的代码准备发布到生产时，更新会容易得多，。此外，所有任务都在应用程序上下文中运行，而由`cron`调用的 Python 脚本则不会运行。

要添加定期任务，请将以下内容添加到`DevConfig`配置对象中：

```
import datetime
…

CELERYBEAT_SCHEDULE = {
    'log-every-30-seconds': {
        'task': 'webapp.tasks.log',
        'schedule': datetime.timedelta(seconds=30),
        'args': ("Message",)
    },
}
```

此`configuration`变量定义`log`任务应每 30 秒运行一次，并以传递的`args`元组作为参数。任何`timedelta`对象都可以用来定义运行任务的时间间隔。

要运行定期任务，需要另一个名为`beat`的专门工作者。在另一个终端窗口中，运行以下操作：

```
$ celery -A celery_runner beat

```

如果您现在在主`Celery`工作进程中观察终端输出，那么现在应该每 30 秒看到一次日志事件。

如果您的任务需要以更具体的时间间隔运行，例如，6 月的每个星期二的凌晨 3 点和下午 5 点，该怎么办？对于非常特定的间隔，有芹菜`crontab`对象。

为了说明`crontab`对象如何表示间隔，以下是一些示例：

```
>>> from celery.schedules import crontab
# Every midnight
>>> crontab(minute=0, hour=0)
# Once a 5AM, then 10AM, then 3PM, then 8PM
>>> crontab(minute=0, hour=[5, 10, 15, 20])
# Every half hour
>>> crontab(minute='*/30')
# Every Monday at even numbered hours and 1AM
>>> crontab(day_of_week=1, hour ='*/2, 1')

```

该对象具有以下参数：

*   `minute`
*   `hour`
*   一周中的第二天
*   `day_of_month`
*   `month_of_year`

每个参数都可以接受各种输入。对于纯整数，它们的操作与对象`timedelta`非常相似，但它们也可以接受字符串和列表。当传递列表时，任务将在列表中的每一时刻执行。当以**/x*的形式传递字符串时，该任务将在模运算返回零的每一刻执行。此外，这两种形式可以组合起来形成一个逗号分隔的整数和除法字符串。

# 监控芹菜

当我们的代码被推送到服务器时，我们的`Celery`工作者将不会在终端窗口中运行，它将作为后台任务运行。正因为如此，芹菜提供了许多命令行参数来监控`Celery`工作者和任务的状态。这些命令采用以下形式：

```
$ celery –A celery_runner <command>

```

查看员工状态的主要任务如下：

*   `status`：这会打印正在运行的工人以及他们是否已启动
*   `result`：当传递任务 id 时，显示任务的返回值和最终状态
*   `purge`：使用此选项，将删除代理中的所有消息
*   `inspect active`：列出所有活动任务
*   `inspect scheduled`：列出了使用`eta`参数计划的所有任务
*   `inspect registered`：列出所有等待处理的任务
*   `inspect stats`：返回一个包含当前运行的 worker 和代理统计信息的字典

## 基于 Web 的花卉监测

**Flower**是基于 web 的芹菜实时管理工具。在 Flower 中，可以监视所有活动、排队和已完成的任务。Flower 还提供了关于每个图在队列中停留了多长时间、执行了多长时间以及每个任务的参数的图表和统计信息。

要安装花，请使用`pip`如下：

```
$ pip install flower

```

要运行它，只需将`flower`视为芹菜命令，如下所示：

```
$ celery flower -A celery_runner --loglevel=info

```

现在，打开浏览器至`http://localhost:5555`。在任务运行时，最好熟悉界面，因此请转到命令行并键入以下内容：

```
>>> sig = chord(
 group(multiply.s(i, i+5) for i in xrange(10000)),
 log.s()
)
>>> sig.delay()

```

您的工作进程现在将开始处理 10000 个任务。当任务运行时，浏览不同的页面，看看 Flower 在工作时是如何与工作人员交互的。

# 创建提醒应用程序

让我们来看看芹菜中的一些真实例子。假设我们网站上的另一个页面现在需要提醒功能。用户可以创建提醒，在指定时间将电子邮件发送到指定位置。我们需要一个模型、一个任务，以及在每次创建模型时自动调用任务的方法。

让我们从以下基本 SQLAlchemy 模型开始：

```
class Reminder(db.Model):
    id = db.Column(db.Integer(), primary_key=True)
    date = db.Column(db.DateTime())
    email = db.Column(db.String())
    text = db.Column(db.Text())

    def __repr__(self):
        return "<Reminder '{}'>".format(self.text[:20])
```

现在我们需要一个任务，该任务将向模型中的位置发送电子邮件。在我们的`tasks.py`文件中，添加以下任务：

```
import smtplib
from email.mime.text import MIMEText

@celery.task(
    bind=True,
    ignore_result=True,
    default_retry_delay=300,
    max_retries=5
)
def remind(self, pk):
    reminder = Reminder.query.get(pk)
    msg = MIMEText(reminder.text)

    msg['Subject'] = "Your reminder"
    msg['From'] = your_email
    msg['To'] = reminder.email

    try:
        smtp_server = smtplib.SMTP('localhost')
        smtp_server.starttls()
        smtp_server.login(user, password)
        smtp_server.sendmail(
            your_email, 
            [reminder.email],
            msg.as_string()
        )
        smtp_server.close()

        return
    except Exception, e:
        self.retry(exc=e)
```

注意我们的任务采用主键而不是模型。这是对竞争条件的一种对冲，因为当工作人员最终开始处理已通过的模型时，该模型可能已经过时。您还必须替换占位符电子邮件，并使用自己的登录信息登录。

当用户创建提醒模型时，如何调用任务？我们将使用名为`events`的 SQLAlchemy 功能。SQLAlchemy 允许我们在模型上注册回调，当对模型进行特定更改时，将调用回调。我们的任务将使用`after_insert`事件，该事件在新数据输入数据库后调用，无论模型是全新的还是正在更新的。

我们需要在`tasks.py`中进行回调：

```
def on_reminder_save(mapper, connect, self):
    remind.apply_async(args=(self.id,), eta=self.date)
```

现在，在`__init__.py`中，我们将在我们的模型上注册我们的回调：

```
from sqlalchemy import event
from .tasks import on_reminder_save

def create_app(object_name):
    app = Flask(__name__)
    app.config.from_object(object_name)

    db.init_app(app)
    event.listen(Reminder, 'after_insert', on_reminder_save)
    …
```

现在，每保存一个模型时，就会注册一个任务，该任务将向我们的用户发送一封电子邮件。

# 创建每周摘要

比如说我们的博客有很多人不使用 RSS，他们更喜欢邮件列表，这是一个庞大的用户群体。我们需要一些方法在每周末创建一个新帖子列表，以增加我们网站的流量。为了解决这个问题，我们将创建一个摘要任务，该任务将在每个星期六上午 10 点由一名巡逻工人调用。

首先，在`tasks.py`中，我们创建如下任务：

```
@celery.task(
    bind=True,
    ignore_result=True,
    default_retry_delay=300,
    max_retries=5
)
def digest(self):
    # find the start and end of this week
    year, week = datetime.datetime.now().isocalendar()[0:2]
    date = datetime.date(year, 1, 1)
    if (date.weekday() > 3):
        date = date + datetime.timedelta(days=7 - date.weekday())
    else:
        date = date - datetime.timedelta(days=date.weekday())
    delta = datetime.timedelta(days=(week - 1) * 7)
    start, end = date + delta, date + delta + datetime.timedelta(days=6)

    posts = Post.query.filter(
        Post.publish_date >= start,
        Post.publish_date <= end
    ).all()

    if (len(posts) == 0):
        return

    msg = MIMEText(
        render_template("digest.html", posts=posts),
        'html'
    )

    msg['Subject'] = "Weekly Digest"
    msg['From'] = your_email

    try:
        smtp_server = smtplib.SMTP('localhost')
        smtp_server.starttls()
        smtp_server.login(user, password)
        smtp_server.sendmail(
            your_email,
            [recipients],
            msg.as_string()
        )
        smtp_server.close()

        return
    except Exception, e:
        self.retry(exc=e)
```

我们将还需要在`config.py`中为我们的配置对象添加一个定期计划来管理我们的任务：

```
CELERYBEAT_SCHEDULE = {
    'weekly-digest': {
        'task': 'tasks.digest',
        'schedule': crontab(day_of_week=6, hour='10')
    },
}
```

最后，我们需要我们的电子邮件模板。不幸的是，电子邮件客户端中的 HTML 非常过时。每个电子邮件客户端都有不同的呈现错误和怪癖，找到它们的唯一方法是在所有客户端中打开您的电子邮件。许多电子邮件客户端甚至不支持 CSS，而那些支持少量选择器和属性的客户端。为了弥补这一不足，我们必须使用 10 年前的 web 开发方法，即使用具有内联样式的表进行设计。这是我们的`digest.html`：

```
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html >
    <head>
        <meta http-equiv="Content-Type"
              content="text/html; charset=UTF-8" />
        <meta name="viewport"
              content="width=device-width, initial-scale=1.0"/>
        <title>Weekly Digest</title>
    </head>
    <body>
        <table align="center"
               border="0"
               cellpadding="0"
               cellspacing="0"
               width="500px">
            <tr>
                <td style="font-size: 32px;
                           font-family: Helvetica, sans-serif;
                           color: #444;
                           text-align: center;
                           line-height: 1.65">
                    Weekly Digest
                </td>
            </tr>
            {% for post in posts %}
                <tr>
                    <td style="font-size: 24px;
                               font-family: sans-serif;
                               color: #444;
                               text-align: center;
                               line-height: 1.65">
                        {{ post.title }}
                    </td>
                </tr>
                <tr>
                    <td style="font-size: 14px;
                               font-family: serif;
                               color: #444;
                               line-height:1.65">
                        {{ post.text | truncate(500) | safe }}
                    </td>
                </tr>
                <tr>
                    <td style="font-size: 12px;
                               font-family: serif;
                               color: blue;
                               margin-bottom: 20px">
                        <a href="{{ url_for('.post', post_id=post.id) }}">Read More</a>
                    </td>
                </tr>
            {% endfor %}
        </table>
    </body>
</html>
```

现在，在每周结束时，我们的摘要任务将被调用，它将向邮件列表中的所有用户发送一封电子邮件。

# 总结

芹菜是一个非常强大的任务队列，它允许程序员将较慢任务的处理推迟到另一个进程。现在您已经了解了如何将复杂任务移出 Flask 流程，我们将查看一组 Flask 扩展，这些扩展简化了 Flask 应用程序中的一些常见任务。*